## Report 3: Estimation and Inference of Heterogenous Treatment Effects using Random Forests (Wager & Athey, 2018)

### Student: Lucas Salamanca Fernández
### Code: 20205849

The article titled “Estimation and Inference of Heterogenous Treatment Effects using Random Forests” written by Wager and Athey (2018) introduces a potent nonparametric method for heterogeneous treatment effects with valid asymptotic confidence intervals for the true treatment effect. The purpose of this method is to tackle some of the difficulties that have arisen from pre-analysis protocols in randomized experiments. Specifically, they improve classic nonparametric methods such as nearest-neighbour matching, kernel methods, and series estimation, by applying a random forest approach, allowing for improved performance when modeling interactions in high-dimensions. The random forest method was introduced by Breinman (2001) and works by building a large number of regression trees and averaging their predictions. However, the authors also highlight the limitations of random forests at applying valid asymptotic sampling distributions for creating valid confidence intervals; thus, the authors’ random forest estimation also allow for a tractable asymptotic theory and statistical inference. 

One of the main strengths of the paper is its theoretical advancement on the field, by showing how random forests can have valid asymptotic theory so that confidence intervals can be set for valid causal inference. Specifically, by using the infinitesimal jackknife for random forests, the authors show that the variance estimation is consistent. Additionally, another strength of this paper is the use of honest trees, which means that for each training example $i$, it only uses the response $Y_i$ to estimate the within-leaf treatment effect $τ(x)$. This means that a single point is not used both to create the partition and to calculate the treatment effect, which helps eliminate the correlation between the partitioning criteria and the outcome estimates. Finally, another strength of the paper is the use of simulation to showcase how causal trees allow for a better mean-squared error than classical methods while using valid confidence intervals that capture the true value of the treatment effect. 

However, one weakness of the paper is the bias at the boundaries of the feature space – although already highlighted by the authors –, specifically for the nearest-neighbor-based non-parametric methods. This type of bias issue can reduce the accuracy of confidence intervals and the reliability of the estimates, especially when the sample size is small or when dealing with a large number of covariates. Another weakness is that the paper only develops pointwise confidence intervals for the treatment effect function $τ(x)$, which means that the intervals are valid for individual points and do not cover the entire function. This limits the applicability of the results in global functional estimation settings. 

The main contribution of this paper is the applicability that this type of models can have in everyday policy and decision-making. By making machine learning methods valid in statistical inference – generating valid confidence intervals – better predictions can be made. For example, the authors highlight the use of this type of model to test whether a patient should receive medicare funding for an urgent surgery by creating an accurate prediction on the probability of the patient will survive before the surgery is received. In this case, confidence intervals can be critical for saving someone’s life. 

One further step can be developing splitting rules that are chosen automatically based on the characteristics of the training data and an automation for choosing the parameter s. This can allow for more robust simulations, which can also allow for a better interpretation of the results, as choosing them manually can create some extra bias. 

