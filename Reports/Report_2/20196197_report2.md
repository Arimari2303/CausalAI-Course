### INFERENCE FOR HIGH-DIMENSIONAL SPARSE ECONOMETRIC MODELS
The article by Belloni, Chernozhukov and Hansen (2011) has as a research question _how to perform estimation and inference in econometric models of large dimensions_, i.e. many regressors (very large number of possible explanatory variables). It shows us HDS methods to use a subset of them that are really relevant on a penalty basis, thus being able to improve the prediction or explanation of the dependent variable.

As mentioned, the main focus of this paper is the use of penalization (Lasso) to select the relevant regressors in sparse regression models. Among the strengths of this approach is its ability to handle high dimensional data, a common reality in modern econometrics due to the large availability of detailed data. As mentioned, it is important for analysis and study requiring the use of housing surveys, such as the ENAHO in Peru, censuses, scanner datasets, among others.

Another strength would be that it imposes a sparsity structure on the models, which ensures that only a subset of variables is effectively selected and used, facilitating interpretation and improving computational efficiency. In doing so, we give due prominence to explanatory variables whose beta is non-zero, thus having an effect on the dependent variable. In addition, a key strength is the application of the model in applied econometrics, such as in growth regressions and analysis of returns to education, the paper shows that it has demonstrated its practical utility, unlike, or in comparison to, linear modeling. Moreover, the paper allows robust inference even when there are errors in the selection of regressors.

However, we can mention as a weakness of the approach to select the relevant regressors is that Lasso-based models can be sensitive to the choice of the penalty level, i.e., the inappropriate choice of the σ could end up in overpenalization, especially if the conservative estimation that is a function of the Brianda of the dependent variable is used. Overcriminalization may influence the precision of the estimated coefficients. In addition, the article assumes that the underlying model is at least approximately sparse, which may not always be a valid assumption in all econometric contexts.

This paper advances knowledge on the question of how to perform estimation and inference in high dimensional econometric models, and while some would not consider it a contribution, it provides great support by providing a solid theoretical framework for handling high dimensional problems. The importance of this is also strengthened because this method is increasingly relevant in empirical research, since by using penalty methods such as Lasso, the authors show that it is possible to achieve inference results that are robust to imperfect variable selection even to linear estimation regression. This represents a significant advance, as traditional regression methods are not adequately applicable or fail in the context where there are more variables than observations.

In addition, the authors address the question of how to handle the instrumental variables model and the partially linear model, which extends the applicability of sparse models in econometrics to contexts with greater complexity. In the case of instrumental variables models, an approach is presented that allows working with a large number of instruments, the methods proposed in this article are based on the selection of relevant instruments using penalty techniques, thus allowing to reduce biases, improve efficiency and avoid problems of overfitting and multicollinearity. This is particularly relevant because normally the use of many instruments leads to problems of weak identification, which ends up affecting the precision of the estimates.

As for partially linear models, the authors explore penalty techniques for the automatic identification of important regressors within a large number of nonlinear series terms; in this case they recommend the “double-Post Lasso method”. This approach improves parameter estimation and facilitates inference in these models, providing a solid theoretical basis for handling imperfect term selection.

A valuable next step is to develop methods to automate the choice of the penalty level (parameter that controls how many variables are selected) for the Lasso technique, ensuring that the selected model is the most appropriate one without the need to manually adjust the parameters and incur errors, which could be solved by adaptive algorithms that determine the optimal penalty level based on known characteristics of the database such as its size, correlation and/or noise level. This development would make high-dimensional models more accessible to users, who would not have to rely on exhaustive parameter calibration to obtain reliable results.

Another step would be to include techniques that not only handle linear regression models, but also nonlinear models and dynamic models. Nonlinear models allow capturing more complex relationships between variables, something that frequently occurs in economic phenomena. While the current article focuses on linear and partially linear regression models, the introduction of methods to automatically select relevant terms in a nonlinear setting could provide a more powerful tool for economists, allowing them to make more accurate inferences in scenarios where relationships between variables are nonlinear or subject to discontinuities. Dynamic models also represent a key area to consider, given that many phenomena are time-dependent and exhibit serial dependence. Here, the challenge would be to adapt sparse variable selection methods to dynamic models where variables may have lagged effects and the model structure evolves over time.
