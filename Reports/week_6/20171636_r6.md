# Report 6
### Angela Coapaza (20171636)

## When should you adjust standard errors for clustering?


In this article, Abadie, Athey, Imbens, and Wooldridge aim to answer, in general, the questions: in what situations is it necessary to adjust standard errors for clustering or adujst for heteroskedasticity-robust, and are there alternative methods less conservative than conventional clustering? To answer these questions, the authors establish a new framework for cluster adjustments to standard errors and propose two new variance estimators, one analytic and the other one based on re sampling or bootstrap.

These questions arise because researchers generally cluster standard errors because of concerns about clustering in the assignment mechanism instead of obtain cluster standard errors using clustered sampling, which is recommended in textbooks.

One of the strengths of this article is that the authors succeed in showing that both cluster standard errors and robust standard errors are not appropriate for estimating standard errors in causal effects analyzes by presenting an empirical example of a log-linear regression of college education earnings using data from the 2000 U.S. decenennial census. They conclude that using the proposed new framework they manage to obtain standard errors that are substantially larger than the robust standard errors, but also substantially smaller than the cluster standard errors . Also, they obtein that the proposed variance estimators , the Causal Cluster Variance (CCV) and the two-stage cluster bootstrap (TSCB), perform better than the robust standard error and the cluster standard error (they are more approximated to the normalized standard deviation of the least squares estimator in the baseline design). 

However, the mathematical explanation of these obtained results is difficult to understand. Another weakness is that the empirical example may be out of date. Currently looking to work with new types of databases (such as high-dimensional data) due to the current needs of data scientist. Finally, it is mentioned that the introduction of the he cluster design component of the variance raises a number of issues that need to be discussed in future articles. Within these problems it is found that the dependence structure in the assignment process may have multiple layers, this is why it is necessary to make multi-level clustering adjustments , and that other types of estimators such as the inverse-variance weighted combinations of the between and appropriately weighted within estimators.

Regarding the contributions of this article, we can find three of them: the first is related to the new framework for clustering mentioned above, which is used for regression analysis estimators from a design perspective. This framework divides and grants different functions for clustering in the sampling process and clustering in the assignment process. Likewise,using this framework, the authors find that the data are not informative about the need to adjust for clustering in the sampling, but they do inform about the need to adjust  for clustering in the assignment process.

The second contribution is the comparison between the variances derived from the sampling and allocation process with the robust and cluster variances, which result in the robust standard errors being generally too small, and the cluster standard errors unnecessarily conservative.

The third contribution refers to the new proposed variance estimators, which are the Causal Cluster Variance (CCV) and the Two-Stage Cluster Bootstrap (TSCB). The first variance (CCV) subtracts estimate of the expectations of the within-cluster sums prior to squaring these sums, de-biasing the cluster variance estimator, which is different to what we usually do when calculating the robust variance and the cluster. The second (TSCB) is calculated in two stages: the first consists of determining the number of  treated and untreated units in each cluster of the bootstrap sample and, in the second stage, researchers sample the number of treated and control units from each cluster determined in the first stage.

The next steps to follow in future works should be (1) to replicate this framework, in different types of databases (such as high-dimensionality databases) to check if using the proposed variance estimators we can obtain the best standard error adjustment when clustering and (2) empirical studies are needed to allow us to compare the results of these proposed variance estimators with other types of estimators (such as the inverse-variance weighting), since this article is limited to comparing their proposed estimators only with the least squares and fixed effect estimators.