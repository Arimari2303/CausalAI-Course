The article “Airbnb Price prediction using machine learning and sentiment analysis”, by Rezazadeh, Nikolenko and Rezai (2019) presents the work of Standford University researchers on a model that could predict the price of an Airbnb based on a limited set of features including the specifications of the property, the information on the owner and the review of the customers in the listing. 

However, one of the primary weaknesses in the experiment was the excessive number of features in the dataset that had to be arranged for proper analysis and normalized. Facing a massive heterogenic dataset, only 10% of the data was used, which would later prove to cause some issues in the results of certain models. There were also hidden factors and interactive terms that were deemed impossible to consider as features but had some relevant impact in the price. Furthermore, this paper implements two new ideas for the regression that haven’t been tested before. First of all, the sentiment analysis, as the reviews from the customers are quite the important factor in the pricing of the Airbnb, they were analysed and assigned a score so that they too could be included as an important new feature. A new model, the Neural Network, was also tested and compared to other more traditional models. As new variables, while they make a great contribution to the advancement of knowledge in the area, the outcomes of their implementation are not always as easy to predict. 

Despite these difficulties, two set of variables were created in addition to the simpler and more wide-spread method of manual selection. One of them tuned the coefficient of linear regression with Lasso Regularization while the other set was defined by the lowest p-values of a regular linear regression model. The training of the three models showed that the two sets created outperformed the traditional manual one, with Lasso Regularization being the one with the highest R2 score and therefore being the one to explain the results better. For their analysis of the prices, 5 models were implemented: Ridge Regression, K-means clustering with Ridge Regression, Support Vector Regression, Gradient Boosting Tree Ensemble and the previously mentioned Neural Network; they were all compared to the baseline of simple Linear Regression In their results, Support Vector Regression had the best performance with the highest R2 score and the smallest Mean Square Error in both the train and test split.

In conclusion, Rezazadeh, Nikolenko and Rezai’s paper has indeed showed that Support Vector Regression model using a Lasso-based feature set can predict prices of an Airbnb with acceptable accuracy and is far superior to the more common, manual, method. Lasso Regulation reduced the variation significantly and SVR performed great in the train and test splits. Finally, the authors themselves acknowledge that if other works want to further their studies on this data set, they could include other selection schemes in the study, more tests with neural net architectures or acquire more training samples to improve the performance of the K-means clustering with Ridge Regression model. The last two suggestions are based on their results with these two models, as the number of training samples was insufficient. 

20180782
Lizárraga Nagahama, Sophie


1) 4 PTS
2) 3 PTS
3) 2 PTS
4) 5 PTS

GRADE = 14