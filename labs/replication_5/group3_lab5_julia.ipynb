{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "using DataFrames\n",
    "using CSV\n",
    "using StatsPlots\n",
    "using Statistics\n",
    "\n",
    "using StatsModels\n",
    "using GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 15 columns (omitted printing of 8 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>y</th><th>w</th><th>gender_female</th><th>gender_male</th><th>gender_transgender</th><th>ethnicgrp_asian</th><th>ethnicgrp_black</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>3</th><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>4</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& y & w & gender\\_female & gender\\_male & gender\\_transgender & ethnicgrp\\_asian & ethnicgrp\\_black & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t2 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t4 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 1 & 1 & 1 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×15 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m y     \u001b[0m\u001b[1m w     \u001b[0m\u001b[1m gender_female \u001b[0m\u001b[1m gender_male \u001b[0m\u001b[1m gender_transgender \u001b[0m\u001b[1m ethnicgrp\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64         \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64              \u001b[0m\u001b[90m Int64    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1      1              0            1                   0            ⋯\n",
       "   2 │     0      0              0            1                   0\n",
       "   3 │     0      1              0            1                   0\n",
       "   4 │     0      0              1            0                   0\n",
       "   5 │     1      1              1            0                   0            ⋯\n",
       "\u001b[36m                                                              10 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and see first observations\n",
    "df = CSV.read(\"C:\\\\Users\\\\juanl\\\\OneDrive\\\\Desktop\\\\hg\\\\data\\\\processed_esti.csv\", DataFrame)\n",
    "first(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>15×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">y</td><td style = \"text-align: right;\">0.351926</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">w</td><td style = \"text-align: right;\">0.529615</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">gender_female</td><td style = \"text-align: right;\">0.584244</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">gender_male</td><td style = \"text-align: right;\">0.413456</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">gender_transgender</td><td style = \"text-align: right;\">0.00230017</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">ethnicgrp_asian</td><td style = \"text-align: right;\">0.0638298</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">ethnicgrp_black</td><td style = \"text-align: right;\">0.0862565</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">ethnicgrp_mixed_multiple</td><td style = \"text-align: right;\">0.0885566</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">ethnicgrp_other</td><td style = \"text-align: right;\">0.013226</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">ethnicgrp_white</td><td style = \"text-align: right;\">0.748131</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">partners1</td><td style = \"text-align: right;\">0.296722</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">postlaunch</td><td style = \"text-align: right;\">0.516964</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">msm</td><td style = \"text-align: right;\">0.130535</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: left;\">age</td><td style = \"text-align: right;\">23.1064</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: left;\">imd_decile</td><td style = \"text-align: right;\">3.47154</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Int64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Int64 & Float64 & Int64 & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & y & 0.351926 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t2 & w & 0.529615 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t3 & gender\\_female & 0.584244 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t4 & gender\\_male & 0.413456 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t5 & gender\\_transgender & 0.00230017 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t6 & ethnicgrp\\_asian & 0.0638298 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t7 & ethnicgrp\\_black & 0.0862565 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t8 & ethnicgrp\\_mixed\\_multiple & 0.0885566 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t9 & ethnicgrp\\_other & 0.013226 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t10 & ethnicgrp\\_white & 0.748131 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t11 & partners1 & 0.296722 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t12 & postlaunch & 0.516964 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t13 & msm & 0.130535 & 0 & 0.0 & 1 & 0 & Int64 \\\\\n",
       "\t14 & age & 23.1064 & 16 & 23.0 & 30 & 0 & Int64 \\\\\n",
       "\t15 & imd\\_decile & 3.47154 & 1 & 3.0 & 9 & 0 & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m15×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable                 \u001b[0m\u001b[1m mean        \u001b[0m\u001b[1m min   \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max   \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "     │\u001b[90m Symbol                   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ y                          0.351926        0      0.0      1         0  ⋯\n",
       "   2 │ w                          0.529615        0      1.0      1         0\n",
       "   3 │ gender_female              0.584244        0      1.0      1         0\n",
       "   4 │ gender_male                0.413456        0      0.0      1         0\n",
       "   5 │ gender_transgender         0.00230017      0      0.0      1         0  ⋯\n",
       "   6 │ ethnicgrp_asian            0.0638298       0      0.0      1         0\n",
       "   7 │ ethnicgrp_black            0.0862565       0      0.0      1         0\n",
       "   8 │ ethnicgrp_mixed_multiple   0.0885566       0      0.0      1         0\n",
       "   9 │ ethnicgrp_other            0.013226        0      0.0      1         0  ⋯\n",
       "  10 │ ethnicgrp_white            0.748131        0      1.0      1         0\n",
       "  11 │ partners1                  0.296722        0      0.0      1         0\n",
       "  12 │ postlaunch                 0.516964        0      1.0      1         0\n",
       "  13 │ msm                        0.130535        0      0.0      1         0  ⋯\n",
       "  14 │ age                       23.1064         16     23.0     30         0\n",
       "  15 │ imd_decile                 3.47154         1      3.0      9         0\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>921 rows × 14 columns (omitted printing of 8 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>w</th><th>gender_female</th><th>gender_male</th><th>gender_transgender</th><th>ethnicgrp_asian</th><th>ethnicgrp_black</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>2</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>3</th><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><th>4</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>5</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>7</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><th>8</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>9</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>10</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>11</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>12</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><th>13</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>14</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>15</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>16</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>17</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>18</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>19</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>20</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>21</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><th>22</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>23</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>24</th><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><th>25</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>26</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>27</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>28</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>29</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th>30</th><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& w & gender\\_female & gender\\_male & gender\\_transgender & ethnicgrp\\_asian & ethnicgrp\\_black & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t2 & 1 & 0 & 1 & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t3 & 1 & 1 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t4 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t6 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t7 & 1 & 1 & 0 & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t8 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t9 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t10 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t11 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t12 & 1 & 1 & 0 & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t13 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t14 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t15 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t16 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t17 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t18 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t19 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t20 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t21 & 1 & 0 & 1 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t22 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t23 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t24 & 1 & 0 & 1 & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t25 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t26 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t27 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t28 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t29 & 1 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t30 & 1 & 1 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m921×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m w     \u001b[0m\u001b[1m gender_female \u001b[0m\u001b[1m gender_male \u001b[0m\u001b[1m gender_transgender \u001b[0m\u001b[1m ethnicgrp_asian \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64         \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64              \u001b[0m\u001b[90m Int64           \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │     1              0            1                   0                0  ⋯\n",
       "   2 │     1              0            1                   0                0\n",
       "   3 │     1              1            0                   0                1\n",
       "   4 │     1              0            1                   0                0\n",
       "   5 │     1              1            0                   0                0  ⋯\n",
       "   6 │     1              0            1                   0                0\n",
       "   7 │     1              1            0                   0                0\n",
       "   8 │     1              0            1                   0                0\n",
       "   9 │     1              0            1                   0                0  ⋯\n",
       "  10 │     1              0            1                   0                0\n",
       "  11 │     1              1            0                   0                0\n",
       "  ⋮  │   ⋮          ⋮             ⋮               ⋮                  ⋮         ⋱\n",
       " 912 │     1              1            0                   0                0\n",
       " 913 │     1              0            1                   0                0  ⋯\n",
       " 914 │     1              0            1                   0                0\n",
       " 915 │     1              0            1                   0                0\n",
       " 916 │     1              0            1                   0                0\n",
       " 917 │     1              1            0                   0                0  ⋯\n",
       " 918 │     1              1            0                   0                0\n",
       " 919 │     1              1            0                   0                0\n",
       " 920 │     1              1            0                   0                0\n",
       " 921 │     1              1            0                   0                0  ⋯\n",
       "\u001b[36m                                                  9 columns and 900 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control = select(filter(row -> row[:w] == 0, df), Not(:y))\n",
    "treatment = select(filter(row -> row[:w] == 1, df), Not(:y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_descriptive_stats (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, Statistics\n",
    "\n",
    "# Function to get descriptive statistics\n",
    "function get_descriptive_stats(group::DataFrame, column::Symbol)\n",
    "    if column == :age\n",
    "        count_val = count(!ismissing, group[:, column])\n",
    "    else\n",
    "        count_val = sum(group[:, column] .== 1)\n",
    "    end\n",
    "    mean_val = mean(group[:, column])\n",
    "    std_val = std(group[:, column])\n",
    "    return count_val, mean_val, std_val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Tuple{Int64, Float64, Float64}} with 13 entries:\n",
       "  :gender_female            => (541, 0.587405, 0.492569)\n",
       "  :postlaunch               => (512, 0.555917, 0.497133)\n",
       "  :ethnicgrp_other          => (9, 0.00977199, 0.0984226)\n",
       "  :imd_decile               => (36, 3.46037, 1.46584)\n",
       "  :ethnicgrp_mixed_multiple => (78, 0.0846906, 0.278572)\n",
       "  :partners1                => (277, 0.30076, 0.458838)\n",
       "  :ethnicgrp_black          => (74, 0.0803474, 0.271978)\n",
       "  :ethnicgrp_white          => (694, 0.753529, 0.43119)\n",
       "  :gender_transgender       => (3, 0.00325733, 0.0570109)\n",
       "  :gender_male              => (377, 0.409338, 0.491979)\n",
       "  :msm                      => (114, 0.123779, 0.329508)\n",
       "  :age                      => (921, 23.1585, 3.53874)\n",
       "  :ethnicgrp_asian          => (66, 0.0716612, 0.258066)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = setdiff(Symbol.(names(df)), [:w, :y])\n",
    "control_stats = Dict(var => get_descriptive_stats(control, var) for var in variables)\n",
    "treatment_stats = Dict(var => get_descriptive_stats(treatment, var) for var in variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Tuple{Int64, Float64, Float64}} with 13 entries:\n",
       "  :gender_female            => (475, 0.580685, 0.493749)\n",
       "  :postlaunch               => (387, 0.473105, 0.499582)\n",
       "  :ethnicgrp_other          => (14, 0.0171149, 0.129779)\n",
       "  :imd_decile               => (37, 3.48411, 1.48608)\n",
       "  :ethnicgrp_mixed_multiple => (76, 0.0929095, 0.290483)\n",
       "  :partners1                => (239, 0.292176, 0.455041)\n",
       "  :ethnicgrp_black          => (76, 0.0929095, 0.290483)\n",
       "  :ethnicgrp_white          => (607, 0.742054, 0.437772)\n",
       "  :gender_transgender       => (1, 0.00122249, 0.0349642)\n",
       "  :gender_male              => (342, 0.418093, 0.493547)\n",
       "  :msm                      => (113, 0.138142, 0.34526)\n",
       "  :age                      => (818, 23.0477, 3.59401)\n",
       "  :ethnicgrp_asian          => (45, 0.0550122, 0.228144)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Non-Linear Methods DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(\"StatsModels\")\n",
    "Pkg.add(\"GLM\")\n",
    "Pkg.add(\"MLJ\")\n",
    "Pkg.add(\"XGBoost\")\n",
    "Pkg.add(\"MLJXGBoostInterface\")\n",
    "Pkg.add(\"MLJGLMInterface\")\n",
    "Pkg.add(\"Lasso\")\n",
    "Pkg.add(\"GLMNet\")\n",
    "Pkg.add(\"CovarianceMatrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m CSV\n",
      "\u001b[32m  ✓ \u001b[39mCSV\n",
      "  1 dependency successfully precompiled in 9 seconds. 26 already precompiled.\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m StatsModels\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Given StatsModels was explicitly requested, output will be shown live \u001b[0K\n",
      "\u001b[0KWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "\u001b[0KERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[33m  ? \u001b[39mStatsModels\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling StatsModels [3eaba693-59b7-5ba5-a881-562e759f1c8d]\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "ERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing StatsModels [3eaba693-59b7-5ba5-a881-562e759f1c8d].\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m StatsFuns\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Given StatsFuns was explicitly requested, output will be shown live \u001b[0K\n",
      "\u001b[0KWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "\u001b[0KERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c]\n",
      "WARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "ERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c].\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m GLM\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mStatsModels\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Given GLM was explicitly requested, output will be shown live \u001b[0K\n",
      "\u001b[0KWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "\u001b[0KERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[33m  ? \u001b[39mGLM\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling GLM [38e38edf-8417-5370-95a0-9cbb8c7f171a]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule StatsFuns with build ID ffffffff-ffff-ffff-0001-616a4687cd8a is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1948\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing GLM [38e38edf-8417-5370-95a0-9cbb8c7f171a].\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m Distributions\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Given Distributions was explicitly requested, output will be shown live \u001b[0K\n",
      "\u001b[0KWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\n",
      "\u001b[0KERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Distributions [31c24e10-a181-5473-b8eb-7969acd0382f]\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule StatsFuns with build ID ffffffff-ffff-ffff-0001-616a4687cd8a is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean StatsFuns [4c63d2b9-4356-54db-8cca-17b64c39e42c] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1948\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSkipping precompilation since __precompile__(false). Importing Distributions [31c24e10-a181-5473-b8eb-7969acd0382f].\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using Statistics\n",
    "using StatsModels\n",
    "using GLM\n",
    "using Random\n",
    "using StatsBase\n",
    "using LinearAlgebra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of y:\n",
      "[0; 0; 0; 0; 1;;]\n",
      "First few rows of d:\n",
      "[1; 1; 0; 1; 1;;]\n",
      "First few rows of x:\n",
      "[1 0 0 0 0 0 0 1 1 0 0 25 6; 0 1 0 0 0 0 0 1 0 0 1 28 5; 1 0 0 0 0 0 0 1 1 1 0 17 6; 1 0 0 0 0 0 0 1 0 1 0 25 2; 1 0 0 0 0 0 0 1 0 0 0 23 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = \"C:\\\\Users\\\\juanl\\\\OneDrive\\\\Desktop\\\\hg\\\\data\\\\processed_esti.csv\"\n",
    "DML = CSV.read(file_path, DataFrame)\n",
    "\n",
    "Random.seed!(1234)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "n = nrow(DML)\n",
    "training = sample(1:n, round(Int, 0.75 * n), replace=false)\n",
    "data_train = DML[training, :]\n",
    "data_test = DML[setdiff(1:n, training), :]\n",
    "\n",
    "# Extract the test outcome\n",
    "Y_test = data_test.y\n",
    "\n",
    "# Extract matrices for outcome, treatment, and controls\n",
    "y = reshape(data_train[:, 1], :, 1)         # outcome: growth rate\n",
    "d = reshape(data_train[:, 2], :, 1)         # treatment: initial wealth\n",
    "x = Matrix(data_train[:, Not([1, 2])])      # controls: country characteristics\n",
    "\n",
    "# Display the first few rows to verify\n",
    "println(\"First few rows of y:\")\n",
    "println(y[1:5, :])\n",
    "println(\"First few rows of d:\")\n",
    "println(d[1:5, :])\n",
    "println(\"First few rows of x:\")\n",
    "println(x[1:5, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScikitLearnBase ─ v0.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DecisionTree ──── v0.12.4\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\juanl\\.julia\\environments\\v1.10\\Project.toml`\n",
      "  \u001b[90m[7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.12.4\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\juanl\\.julia\\environments\\v1.10\\Manifest.toml`\n",
      "  \u001b[90m[7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.12.4\u001b[39m\n",
      "  \u001b[90m[6e75b9c4] \u001b[39m\u001b[92m+ ScikitLearnBase v0.5.0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mScikitLearnBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorVectorSpace → SpecialFunctionsExt\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mPyCall\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mBinaryProvider\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLatexify → DataFramesExt\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39mMLJXGBoostInterface\n",
      "\u001b[32m  ✓ \u001b[39mDecisionTree\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mSnappy\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mStatsModels\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mExcelReaders\u001b[39m\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mParquet\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mGLM\n",
      "\u001b[33m  ? \u001b[39mCovarianceMatrices\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mExcelFiles\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mGLMNet\n",
      "\u001b[91m  ✗ \u001b[39m\u001b[90mParquetFiles\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJGLMInterface\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJBase\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mLasso\n",
      "\u001b[91m  ✗ \u001b[39mQueryverse\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJIteration\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJModels\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJTuning\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJSerialization\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJEnsembles\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJ\n",
      "  4 dependencies successfully precompiled in 42 seconds. 284 already precompiled.\n",
      "  \u001b[33m12\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n",
      "  \u001b[33m15\u001b[39m dependencies failed but may be precompilable after restarting julia\n",
      "  \u001b[33m15\u001b[39m dependencies had output during precompilation:\u001b[33m\n",
      "┌ \u001b[39mStatsFuns\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mGLMNet\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJ\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJIteration\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJGLMInterface\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mCovarianceMatrices\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mLasso\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mStatsModels\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJTuning\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJBase\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJModels\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJEnsembles\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mGLM\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mMLJSerialization\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\u001b[33m\n",
      "┌ \u001b[39mDistributions\u001b[33m\n",
      "│  \u001b[39mWARNING: Method definition (::Type{Base.MPFR.BigFloat})(Base.Irrational{:twoπ}) in module IrrationalConstants at irrationals.jl:223 overwritten in module StatsFuns on the same line (check for duplicate calls to `include`).\u001b[33m\n",
      "│  \u001b[39mERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\u001b[33m\n",
      "└  \u001b[39m\n",
      "  \u001b[91m9\u001b[39m dependencies errored.\n",
      "  For a report of the errors see `julia> err`. To retry use `pkg> precompile`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"DecisionTree\")\n",
    "\n",
    "using DecisionTree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML function for Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DML2_for_PLM_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using DecisionTree\n",
    "using Statistics\n",
    "\n",
    "function DML2_for_PLM_tree(data_train, dreg, yreg; nfold=10)\n",
    "    nobs = nrow(data_train)  # number of observations\n",
    "    foldid = repeat(1:nfold, ceil(Int, nobs/nfold))[shuffle(1:nobs)]  # define fold indices\n",
    "    I = [findall(foldid .== i) for i in 1:nfold]  # split observation indices into folds\n",
    "    ytil = fill(NaN, nobs)\n",
    "    dtil = fill(NaN, nobs)\n",
    "    println(\"fold: \")\n",
    "\n",
    "    for b in 1:nfold\n",
    "        # Exclude the current fold for training\n",
    "        datitanow = data_train[setdiff(1:nobs, I[b]), Not(:d)]\n",
    "        datitanoy = data_train[setdiff(1:nobs, I[b]), Not(:y)]\n",
    "        # Current fold for prediction\n",
    "        datitanowpredict = data_train[I[b], Not(:d)]\n",
    "        datitanoypredict = data_train[I[b], Not(:y)]\n",
    "\n",
    "        # Fit models\n",
    "        dfit = dreg(datitanoy)\n",
    "        yfit = yreg(datitanow)\n",
    "        # Make predictions\n",
    "        dhat = predict(dfit, DataFrame(datitanoypredict, :auto))\n",
    "        yhat = predict(yfit, DataFrame(datitanowpredict, :auto))\n",
    "        # Record residuals\n",
    "        dtil[I[b]] .= data_train[I[b], :d] .- dhat\n",
    "        ytil[I[b]] .= data_train[I[b], :y] .- yhat\n",
    "        print(\"$b \")\n",
    "    end\n",
    "\n",
    "    # Ensure ytil and dtil are column vectors\n",
    "    ytil = reshape(ytil, :, 1)\n",
    "    dtil = reshape(dtil, :, 1)\n",
    "\n",
    "    # Regress one residual on the other\n",
    "    rfit = lm(@formula(ytil ~ dtil), DataFrame(hcat(ytil, dtil), :auto))\n",
    "    coef_est = coef(rfit)[2]\n",
    "    se = sqrt(vcov(HC0, rfit)[2, 2])\n",
    "    println(\"\\ncoef (se) = $coef_est ($se)\")\n",
    "\n",
    "    return (coef_est = coef_est, se = se, dtil = dtil, ytil = ytil)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML function for Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DML2_for_PLM_boosttree (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using MLJ\n",
    "using XGBoost\n",
    "\n",
    "function DML2_for_PLM_boosttree(data_train, dreg, yreg; nfold=10)\n",
    "    nobs = nrow(data_train)  # number of observations\n",
    "    foldid = repeat(1:nfold, ceil(Int, nobs/nfold))[shuffle(1:nobs)]  # define fold indices\n",
    "    I = [findall(foldid .== i) for i in 1:nfold]  # split observation indices into folds\n",
    "    ytil = fill(NaN, nobs)\n",
    "    dtil = fill(NaN, nobs)\n",
    "    println(\"fold: \")\n",
    "\n",
    "    for b in 1:nfold\n",
    "        # Exclude the current fold for training\n",
    "        datitanow = data_train[setdiff(1:nobs, I[b]), Not(:d)]\n",
    "        datitanoy = data_train[setdiff(1:nobs, I[b]), Not(:y)]\n",
    "        # Current fold for prediction\n",
    "        datitanowpredict = data_train[I[b], Not(:d)]\n",
    "        datitanoypredict = data_train[I[b], Not(:y)]\n",
    "\n",
    "        # Fit models\n",
    "        dfit = dreg(datitanoy)\n",
    "        best_boostt = fit!(dfit, verbosity=0)  # fit the model\n",
    "        yfit = yreg(datitanow)\n",
    "        best_boosty = fit!(yfit, verbosity=0)  # fit the model\n",
    "\n",
    "        # Make predictions\n",
    "        dhat = MLJ.predict(best_boostt, DataFrame(datitanoypredict, :auto))\n",
    "        yhat = MLJ.predict(best_boosty, DataFrame(datitanowpredict, :auto))\n",
    "\n",
    "        # Record residuals\n",
    "        dtil[I[b]] .= data_train[I[b], :d] .- dhat\n",
    "        ytil[I[b]] .= data_train[I[b], :y] .- yhat\n",
    "        print(\"$b \")\n",
    "    end\n",
    "\n",
    "    # Ensure ytil and dtil are column vectors\n",
    "    ytil = reshape(ytil, :, 1)\n",
    "    dtil = reshape(dtil, :, 1)\n",
    "\n",
    "    # Regress one residual on the other\n",
    "    rfit = lm(@formula(ytil ~ dtil), DataFrame(hcat(ytil, dtil), :auto))\n",
    "    coef_est = coef(rfit)[2]\n",
    "    se = sqrt(vcov(HC0, rfit)[2, 2])\n",
    "    println(\"\\ncoef (se) = $coef_est ($se)\")\n",
    "\n",
    "    return (coef_est = coef_est, se = se, dtil = dtil, ytil = ytil)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML function for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DML2_for_PLM (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "using DataFrames\n",
    "using CSV\n",
    "using GLM\n",
    "using Random\n",
    "using StatsBase\n",
    "using GLMNet\n",
    "using Statistics\n",
    "\n",
    "function DML2_for_PLM(x, d, y, dreg, yreg; nfold=10)\n",
    "    nobs = size(x, 1)  # number of observations\n",
    "    foldid = repeat(1:nfold, ceil(Int, nobs/nfold))[shuffle(1:nobs)]  # define fold indices\n",
    "    I = [findall(foldid .== i) for i in 1:nfold]  # split observation indices into folds\n",
    "    ytil = fill(NaN, nobs)\n",
    "    dtil = fill(NaN, nobs)\n",
    "    println(\"fold: \")\n",
    "\n",
    "    for b in 1:nfold\n",
    "        # Exclude the current fold for training\n",
    "        train_indices = setdiff(1:nobs, I[b])\n",
    "        test_indices = I[b]\n",
    "\n",
    "        # Fit models\n",
    "        dfit = dreg(x[train_indices, :], d[train_indices])\n",
    "        yfit = yreg(x[train_indices, :], y[train_indices])\n",
    "\n",
    "        # Make predictions\n",
    "        dhat = GLMNet.predict(dfit, x[test_indices, :])\n",
    "        yhat = GLMNet.predict(yfit, x[test_indices, :])\n",
    "\n",
    "        # Record residuals\n",
    "        dtil[test_indices] .= d[test_indices] .- dhat\n",
    "        ytil[test_indices] .= y[test_indices] .- yhat\n",
    "        print(\"$b \")\n",
    "    end\n",
    "\n",
    "    # Ensure ytil and dtil are column vectors\n",
    "    ytil = vec(ytil)\n",
    "    dtil = vec(dtil)\n",
    "\n",
    "    # Regress one residual on the other\n",
    "    data = DataFrame(ytil = ytil, dtil = dtil)\n",
    "    rfit = lm(@formula(ytil ~ dtil), data)\n",
    "    coef_est = coef(rfit)[2]\n",
    "    se = sqrt(vcov(HC0, rfit)[2, 2])\n",
    "    println(\"\\ncoef (se) = $coef_est ($se)\")\n",
    "\n",
    "    return Dict(\"coef.est\" => coef_est, \"se\" => se, \"dtil\" => dtil, \"ytil\" => ytil)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: \n",
      "1 2 3 4 5 6 7 8 9 10 "
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `coef` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `coef` not defined",
      "",
      "Stacktrace:",
      " [1] DML2_for_PLM(x::Matrix{Float64}, d::Vector{Float64}, y::Vector{Float64}, dreg::var\"#18#19\", yreg::var\"#20#21\"; nfold::Int64)",
      "   @ Main .\\In[8]:43",
      " [2] top-level scope",
      "   @ In[9]:8"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define Lasso regression functions\n",
    "dreg_lasso = (x, d) -> GLMNet.glmnet(x, d, alpha=1.0, lambda=[0.1])\n",
    "yreg_lasso = (x, y) -> GLMNet.glmnet(x, y, alpha=1.0, lambda=[0.1])\n",
    "\n",
    "# Apply DML with Lasso\n",
    "DML2_lasso = DML2_for_PLM(x, d, y, dreg_lasso, yreg_lasso, nfold=10)\n",
    "\n",
    "# Extract results\n",
    "coef_lasso = DML2_lasso[\"coef.est\"]\n",
    "se_lasso = DML2_lasso[\"se\"]\n",
    "prRes_lassoD = mean((DML2_lasso[\"dtil\"]).^2)\n",
    "prRes_lassoY = mean((DML2_lasso[\"ytil\"]).^2)\n",
    "\n",
    "# Format results\n",
    "prRes_lasso = DataFrame(\n",
    "    Estimate = coef_lasso,\n",
    "    `Standard Error` = se_lasso,\n",
    "    `RMSE D` = sqrt(prRes_lassoD),\n",
    "    `RMSE Y` = sqrt(prRes_lassoY)\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "println(prRes_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message treatment providing information about Internet-accessed sexually transmitted\n",
    "infection testing predicts an increase in the probability that a person will get tested\n",
    "by 25.13 percentage points compared to receiving information about nearby clinics offering\n",
    "in-person testing.\n",
    "By providing both groups with information about testing, we mitigate the potential reminder\n",
    "effect, as both groups are equally prompted to consider testing. This approach allows us to\n",
    "isolate the impact of the type of information \"Internet-accessed testing\" versus \"in-person clinic\n",
    "testing\" on the likelihood of getting tested. Through randomized assignment, we establish causality\n",
    "rather than mere correlation, confirming that the intervention's effect is driven by the unique\n",
    "advantages of Internet-accessed testing, such as increased privacy, reduced embarrassment, and\n",
    "convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: ArgumentError: interpolation with $ not supported in @formula.  Use @eval @formula(...) instead.\nin expression starting at In[23]:4",
     "output_type": "error",
     "traceback": [
      "LoadError: ArgumentError: interpolation with $ not supported in @formula.  Use @eval @formula(...) instead.\nin expression starting at In[23]:4",
      "",
      "Stacktrace:",
      " [1] catch_dollar",
      "   @ C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:20 [inlined]",
      " [2] parse!(ex::Expr, rewrites::Vector{DataType})",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:180",
      " [3] parse!(ex::Expr, rewrites::Vector{DataType})",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:197",
      " [4] parse!(x::Expr)",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:176",
      " [5] var\"@formula\"(__source__::LineNumberNode, __module__::Module, ex::Any)",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:63"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the basic formula for the regression tree\n",
    "X_basic = \"gender_transgender + ethnicgrp_asian + ethnicgrp_black + ethnicgrp_mixed_multiple+ ethnicgrp_other + ethnicgrp_white + partners1 + postlaunch + msm + age+ imd_decile\"\n",
    "y_form_tree = @formula(y ~ $(Meta.parse(X_basic)))\n",
    "t_form_tree = @formula(w ~ $(Meta.parse(X_basic)))\n",
    "\n",
    "# Define tree regression functions\n",
    "yreg_tree = (dataa) -> DecisionTreeRegressor(min_samples_leaf=5, max_depth=5).fit(Matrix(dataa[:, Not(:y)]), Vector(dataa[:, :y]))\n",
    "treg_tree = (dataa) -> DecisionTreeRegressor(min_samples_leaf=5, max_depth=5).fit(Matrix(dataa[:, Not(:w)]), Vector(dataa[:, :w]))\n",
    "\n",
    "# Apply DML with regression tree\n",
    "DML2_tree = DML2_for_PLM_tree(data_train, treg_tree, yreg_tree, nfold=10)\n",
    "\n",
    "# Extract results\n",
    "coef_tree = DML2_tree[1]\n",
    "se_tree = DML2_tree[2]\n",
    "prRes_treeD = mean((DML2_tree[3]).^2)\n",
    "prRes_treeY = mean((DML2_tree[4]).^2)\n",
    "\n",
    "# Format results\n",
    "prRes_tree = DataFrame(\n",
    "    Estimate = coef_tree,\n",
    "    `Standard Error` = se_tree,\n",
    "    `RMSE D` = sqrt(prRes_treeD),\n",
    "    `RMSE Y` = sqrt(prRes_treeY)\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "println(prRes_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message treatment providing information about Internet-accessed sexually transmitted\n",
    "infection testing predicts an increase in the probability that a person will get tested\n",
    "by 23.08 percentage points compared to receiving information about nearby clinics offering\n",
    "in-person testing.\n",
    "By providing both groups with information about testing, we mitigate the potential reminder\n",
    "effect, as both groups are equally prompted to consider testing. This approach allows us to\n",
    "isolate the impact of the type of information \"Internet-accessed testing\" versus \"in-person clinic\n",
    "testing\" on the likelihood of getting tested. Through randomized assignment, we establish causality\n",
    "rather than mere correlation, confirming that the intervention's effect is driven by the unique\n",
    "advantages of Internet-accessed testing, such as increased privacy, reduced embarrassment, and\n",
    "convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: ArgumentError: interpolation with $ not supported in @formula.  Use @eval @formula(...) instead.\nin expression starting at In[25]:3",
     "output_type": "error",
     "traceback": [
      "LoadError: ArgumentError: interpolation with $ not supported in @formula.  Use @eval @formula(...) instead.\nin expression starting at In[25]:3",
      "",
      "Stacktrace:",
      " [1] catch_dollar",
      "   @ C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:20 [inlined]",
      " [2] parse!(ex::Expr, rewrites::Vector{DataType})",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:180",
      " [3] parse!(ex::Expr, rewrites::Vector{DataType})",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:197",
      " [4] parse!(x::Expr)",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:176",
      " [5] var\"@formula\"(__source__::LineNumberNode, __module__::Module, ex::Any)",
      "   @ StatsModels C:\\Users\\juanl\\.julia\\packages\\StatsModels\\fK0P3\\src\\formula.jl:63"
     ]
    }
   ],
   "source": [
    "# Set up the basic formula for the boosted tree\n",
    "X_basic = \"gender_transgender + ethnicgrp_asian + ethnicgrp_black + ethnicgrp_mixed_multiple+ ethnicgrp_other + ethnicgrp_white + partners1 + postlaunch + msm + age+ imd_decile\"\n",
    "y_form_tree = @formula(y ~ $(Meta.parse(X_basic)))\n",
    "t_form_tree = @formula(w ~ $(Meta.parse(X_basic)))\n",
    "\n",
    "# Define boosted tree regression functions\n",
    "yreg_treeboost = (dataa) -> machine(XGBoostRegressor(max_depth=2, nrounds=1000, eta=0.01, subsample=0.5), dataa[:, Not(:y)], dataa[:, :y])\n",
    "treg_treeboost = (dataa) -> machine(XGBoostRegressor(max_depth=2, nrounds=1000, eta=0.01, subsample=0.5), dataa[:, Not(:w)], dataa[:, :w])\n",
    "\n",
    "# Apply DML with boosted trees\n",
    "DML2_boosttree = DML2_for_PLM_boosttree(data_train, treg_treeboost, yreg_treeboost, nfold=10)\n",
    "\n",
    "# Extract results\n",
    "coef_boosttree = DML2_boosttree[1]\n",
    "se_boosttree = DML2_boosttree[2]\n",
    "prRes_boosttreeD = mean((DML2_boosttree[3]).^2)\n",
    "prRes_boosttreeY = mean((DML2_boosttree[4]).^2)\n",
    "\n",
    "# Format results\n",
    "prRes_boosttree = DataFrame(\n",
    "    Estimate = coef_boosttree,\n",
    "    `Standard Error` = se_boosttree,\n",
    "    `RMSE D` = sqrt(prRes_boosttreeD),\n",
    "    `RMSE Y` = sqrt(prRes_boosttreeY)\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "println(prRes_boosttree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message treatment providing information about Internet-accessed sexually transmitted\n",
    "infection testing predicts an increase in the probability that a person will get tested\n",
    "by 25.28 percentage points compared to receiving information about nearby clinics offering\n",
    "in-person testing.\n",
    "By providing both groups with information about testing, we mitigate the potential reminder\n",
    "effect, as both groups are equally prompted to consider testing. This approach allows us to\n",
    "isolate the impact of the type of information \"Internet-accessed testing\" versus \"in-person clinic\n",
    "testing\" on the likelihood of getting tested. Through randomized assignment, we establish causality\n",
    "rather than mere correlation, confirming that the intervention's effect is driven by the unique\n",
    "advantages of Internet-accessed testing, such as increased privacy, reduced embarrassment, and\n",
    "convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DML2_for_PLM_RF (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for Double Machine Learning with Partially Linear Model using Random Forest\n",
    "function DML2_for_PLM_RF(data_train, dreg, yreg; nfold=10)\n",
    "    nobs = nrow(data_train)  # number of observations\n",
    "    foldid = repeat(1:nfold, ceil(Int, nobs/nfold))[shuffle(1:nobs)]  # define fold indices\n",
    "    I = [findall(foldid .== i) for i in 1:nfold]  # split observation indices into folds\n",
    "    ytil = fill(NaN, nobs)\n",
    "    dtil = fill(NaN, nobs)\n",
    "    println(\"fold: \")\n",
    "\n",
    "    for b in 1:nfold\n",
    "        # Exclude the current fold for training\n",
    "        train_indices = setdiff(1:nobs, I[b])\n",
    "        test_indices = I[b]\n",
    "\n",
    "        # Fit models\n",
    "        dfit = dreg(x[train_indices, :], d[train_indices])\n",
    "        yfit = yreg(x[train_indices, :], y[train_indices])\n",
    "\n",
    "        # Make predictions\n",
    "        dhat = predict(dfit, x[test_indices, :])\n",
    "        yhat = predict(yfit, x[test_indices, :])\n",
    "\n",
    "        # Record residuals\n",
    "        dtil[test_indices] .= d[test_indices] .- dhat\n",
    "        ytil[test_indices] .= y[test_indices] .- yhat\n",
    "        print(\"$b \")\n",
    "    end\n",
    "\n",
    "    # Ensure ytil and dtil are column vectors\n",
    "    ytil = vec(ytil)\n",
    "    dtil = vec(dtil)\n",
    "\n",
    "    # Regress one residual on the other\n",
    "    data = DataFrame(ytil = ytil, dtil = dtil)\n",
    "    rfit = lm(@formula(ytil ~ dtil), data)\n",
    "    coef_est = coef(rfit)[2]\n",
    "    se = sqrt(vcov(HC0, rfit)[2, 2])\n",
    "    println(\"\\ncoef (se) = $coef_est ($se)\")\n",
    "\n",
    "    return Dict(\"coef.est\" => coef_est, \"se\" => se, \"dtil\" => dtil, \"ytil\" => ytil)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching DML2_for_PLM_RF(::Matrix{Float64}, ::Vector{Float64}, ::Vector{Float64}, ::var\"#55#56\", ::var\"#57#58\"; nfold::Int64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  DML2_for_PLM_RF(::Any, ::Any, ::Any; nfold)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m\u001b[4mIn[26]:2\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DML2_for_PLM_RF(::Matrix{Float64}, ::Vector{Float64}, ::Vector{Float64}, ::var\"#55#56\", ::var\"#57#58\"; nfold::Int64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  DML2_for_PLM_RF(::Any, ::Any, ::Any; nfold)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m\u001b[4mIn[26]:2\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[27]:7"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Random Forest regression functions\n",
    "dreg_RF = (x, d) -> RandomForestRegressor(n_trees=100).fit(x, d)\n",
    "yreg_RF = (x, y) -> RandomForestRegressor(n_trees=100).fit(x, y)\n",
    "\n",
    "# Apply DML with Random Forest\n",
    "DML2_RF = DML2_for_PLM_RF(x, d, y, dreg_RF, yreg_RF, nfold=10)\n",
    "\n",
    "# Extract results\n",
    "coef_RF = DML2_RF[\"coef.est\"]\n",
    "se_RF = DML2_RF[\"se\"]\n",
    "prRes_RFD = mean((DML2_RF[\"dtil\"]).^2)\n",
    "prRes_RFY = mean((DML2_RF[\"ytil\"]).^2)\n",
    "\n",
    "# Format results\n",
    "prRes_RF = DataFrame(\n",
    "    Estimate = coef_RF,\n",
    "    `Standard Error` = se_RF,\n",
    "    `RMSE D` = sqrt(prRes_RFD),\n",
    "    `RMSE Y` = sqrt(prRes_RFY)\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "println(prRes_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message treatment providing information about Internet-accessed sexually transmitted\n",
    "infection testing predicts an increase in the probability that a person will get tested\n",
    "by 24.14 percentage points compared to receiving information about nearby clinics offering\n",
    "in-person testing.\n",
    "By providing both groups with information about testing, we mitigate the potential reminder\n",
    "effect, as both groups are equally prompted to consider testing. This approach allows us to\n",
    "isolate the impact of the type of information \"Internet-accessed testing\" versus \"in-person clinic\n",
    "testing\" on the likelihood of getting tested. Through randomized assignment, we establish causality\n",
    "rather than mere correlation, confirming that the intervention's effect is driven by the unique\n",
    "advantages of Internet-accessed testing, such as increased privacy, reduced embarrassment, and\n",
    "convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Table and Coefficient plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coefficient Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `DML2_lasso` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `DML2_lasso` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[28]:2"
     ]
    }
   ],
   "source": [
    "prRes_D = [\n",
    "    mean((DML2_lasso[\"dtil\"]).^2),\n",
    "    mean((DML2_tree[\"dtil\"]).^2),\n",
    "    mean((DML2_boosttree[\"dtil\"]).^2),\n",
    "    mean((DML2_RF[\"dtil\"]).^2)\n",
    "]\n",
    "\n",
    "prRes_Y = [\n",
    "    mean((DML2_lasso[\"ytil\"]).^2),\n",
    "    mean((DML2_tree[\"ytil\"]).^2),\n",
    "    mean((DML2_boosttree[\"ytil\"]).^2),\n",
    "    mean((DML2_RF[\"ytil\"]).^2)\n",
    "]\n",
    "\n",
    "prRes = hcat(sqrt.(prRes_D), sqrt.(prRes_Y))\n",
    "rownames!(prRes, [\"RMSE D\", \"RMSE Y\"])\n",
    "colnames!(prRes, [\"Lasso\", \"Reg Tree\", \"Boost Tree\", \"Random Forest\"])\n",
    "\n",
    "# Create results table\n",
    "table = zeros(4, 4)\n",
    "\n",
    "# Point Estimate\n",
    "table[1, 1] = DML2_lasso[\"coef.est\"]\n",
    "table[2, 1] = DML2_tree[\"coef.est\"]\n",
    "table[3, 1] = DML2_boosttree[\"coef.est\"]\n",
    "table[4, 1] = DML2_RF[\"coef.est\"]\n",
    "\n",
    "# SE\n",
    "table[1, 2] = DML2_lasso[\"se\"]\n",
    "table[2, 2] = DML2_tree[\"se\"]\n",
    "table[3, 2] = DML2_boosttree[\"se\"]\n",
    "table[4, 2] = DML2_RF[\"se\"]\n",
    "\n",
    "# RMSE Y\n",
    "table[1, 3] = prRes[2, 1]\n",
    "table[2, 3] = prRes[2, 2]\n",
    "table[3, 3] = prRes[2, 3]\n",
    "table[4, 3] = prRes[2, 4]\n",
    "\n",
    "# RMSE D\n",
    "table[1, 4] = prRes[1, 1]\n",
    "table[2, 4] = prRes[1, 2]\n",
    "table[3, 4] = prRes[1, 3]\n",
    "table[4, 4] = prRes[1, 4]\n",
    "\n",
    "# Print results\n",
    "colnames!(table, [\"Estimate\", \"Standard Error\", \"RMSE Y\", \"RMSE D\"])\n",
    "rownames!(table, [\"Lasso\", \"Reg Tree\", \"Boost Tree\", \"Random Forest\"])\n",
    "\n",
    "# Display the table\n",
    "println(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\juanl\\.julia\\environments\\v1.10\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\juanl\\.julia\\environments\\v1.10\\Manifest.toml`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mStatsModels\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mGLM\n",
      "\u001b[33m  ? \u001b[39mCovarianceMatrices\n",
      "\u001b[33m  ? \u001b[39mGLMNet\n",
      "\u001b[33m  ? \u001b[39mMLJGLMInterface\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJBase\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mLasso\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJIteration\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJTuning\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJEnsembles\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJSerialization\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJModels\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJ\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Package plots not found in current path.\n- Run `import Pkg; Pkg.add(\"plots\")` to install the plots package.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package plots not found in current path.\n- Run `import Pkg; Pkg.add(\"plots\")` to install the plots package.",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ .\\loading.jl:1772 [inlined]",
      " [2] macro expansion",
      "   @ .\\lock.jl:267 [inlined]",
      " [3] __require(into::Module, mod::Symbol)",
      "   @ Base .\\loading.jl:1753",
      " [4] #invoke_in_world#3",
      "   @ .\\essentials.jl:926 [inlined]",
      " [5] invoke_in_world",
      "   @ .\\essentials.jl:923 [inlined]",
      " [6] require(into::Module, mod::Symbol)",
      "   @ Base .\\loading.jl:1746"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Plots\")\n",
    "using plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching DataFrame(::typeof(table), ::Vector{String})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:Type}\u001b[39m, ::AbstractVector{<:AbstractString}, \u001b[91m::Integer\u001b[39m; makeunique)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:397\u001b[24m\u001b[39m\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:AbstractVector}\u001b[39m, ::AbstractVector; makeunique, copycols)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:344\u001b[24m\u001b[39m\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:Type}\u001b[39m, ::AbstractVector{<:AbstractString}; ...)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:397\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DataFrame(::typeof(table), ::Vector{String})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:Type}\u001b[39m, ::AbstractVector{<:AbstractString}, \u001b[91m::Integer\u001b[39m; makeunique)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:397\u001b[24m\u001b[39m\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:AbstractVector}\u001b[39m, ::AbstractVector; makeunique, copycols)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:344\u001b[24m\u001b[39m\n\u001b[0m  DataFrame(\u001b[91m::AbstractVector{<:Type}\u001b[39m, ::AbstractVector{<:AbstractString}; ...)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataFrames\u001b[39m \u001b[90mC:\\Users\\juanl\\.julia\\packages\\DataFrames\\JZ7x5\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:397\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[37]:2"
     ]
    }
   ],
   "source": [
    "# Convert `table` to DataFrame\n",
    "table_ci = DataFrame(table, [\"Estimate\", \"Standard Error\", \"RMSE Y\", \"RMSE D\"])\n",
    "table_ci.Method = [\"Lasso\", \"Reg Tree\", \"Boost Tree\", \"Random Forest\"]\n",
    "\n",
    "# Calculate confidence intervals\n",
    "table_ci.CI_Lower_1 = table_ci.Estimate .- 2.576 .* table_ci.\"Standard Error\"\n",
    "table_ci.CI_Upper_1 = table_ci.Estimate .+ 2.576 .* table_ci.\"Standard Error\"\n",
    "table_ci.CI_Lower_5 = table_ci.Estimate .- 1.96 .* table_ci.\"Standard Error\"\n",
    "table_ci.CI_Upper_5 = table_ci.Estimate .+ 1.96 .* table_ci.\"Standard Error\"\n",
    "table_ci.CI_Lower_10 = table_ci.Estimate .- 1.645 .* table_ci.\"Standard Error\"\n",
    "table_ci.CI_Upper_10 = table_ci.Estimate .+ 1.645 .* table_ci.\"Standard Error\"\n",
    "\n",
    "# Plotting\n",
    "plot(table_ci.Method, table_ci.Estimate, seriestype=:scatter, label=\"Estimate\", markersize=4)\n",
    "plot!(table_ci.Method, table_ci.CI_Lower_5, ribbon=(table_ci.CI_Upper_5 .- table_ci.CI_Lower_5), label=\"95% CI\", lw=2, lc=:blue, alpha=0.7)\n",
    "plot!(table_ci.Method, table_ci.CI_Lower_10, ribbon=(table_ci.CI_Upper_10 .- table_ci.CI_Lower_10), label=\"90% CI\", lw=2, lc=:red, alpha=0.7)\n",
    "plot!(table_ci.Method, table_ci.CI_Lower_1, ribbon=(table_ci.CI_Upper_1 .- table_ci.CI_Lower_1), label=\"99% CI\", lw=2, lc=:green, alpha=0.7)\n",
    "title!(\"Estimated Coefficients with Confidence Intervals\")\n",
    "xlabel!(\"Method\")\n",
    "ylabel!(\"Estimate\")\n",
    "theme(:minimal)\n",
    "xticks!(1:4, table_ci.Method)\n",
    "xrotation!(45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the best model, we must compare the RMSEs of the outcome variable Y. In this case, the model with the lowest RMSE for Y\n",
    "is generated by Lasso (0.4716420), whereas the lowest for the treatment is generated by Boosting Trees (0.4983734). Therefore, DML\n",
    "could be employed with Y cleaned using Lasso and the treatment using Boosting Trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
