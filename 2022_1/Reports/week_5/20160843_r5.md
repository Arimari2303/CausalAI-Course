

1. What is the research question of both articles?

Both articles research about the possible biases generated in a regression analysis due to the inclusion of "bad controls", in the context of the study of causal effects.

 
2. What are the strengths and weaknesses of both papers' approaches to responding to that question?

 An important strength of Hunermund, Louw and Caspe (2022) is that the authors demonstrate its theoretical results by a simluation that allows to compare the performance of DML and Lasso, showing that, athough with some differences, both estimation and covariate selection procedures can end up with biased estimations, if bad controls are included in the conditioning set. Also, the authors apply DML to an estimation of gender wage gaps, from data of Blau and Kahn (2017), and show that the inclusion of a bad control can substantially affect the estimated coefficient of interest, giving support to the idea that it is, to say least, dubious to use automated, data driven, covariate selection procedures. 

On the other hand, Cinelli, Forney and Pearl (2022) give numerous graphical examples (DAG's, for Directed Acyclical Graphs) that help to visualize and understand whether it is appropriate to include some covariate Z or not, based on if it behaves as a back-door path (in which case the inclusion would be necessary), a collider (in which case we must not include, if we want an unbiased estimator), or simply a variable that has a correlation with the Treatment, the Outcome and/or with the causal relationship between them.

However, an important weakness of this last document is that, although being extremely illustrative, it only prevents us of what not to do when dealing with the problem of including a covariate or not. Hence, is more of a critique-type of document, rather than one that helps us to get-by when trying to study causal effects. Another probable weakness is that in real applications, the causal effect of X on Y cannot be identified from DAG anaylisis, in which case we can't conclude whether is appropriate to include a covariate Z or not.


3. How do the papers advance knowledge about the question, i.e., what is the contribution? (If you can't find any contributions, ask yourself why the editor and the referees decided to publish the articles).

On the one hand, Hunermund, Louw and Caspe (2022) warn about the using of authomatized covariate selection methods, such as Double Machine Learning (DML), because they rely on the property of *unconfoundedness*, which implies that the **treatment status is conditionally independent of potential outcomes**. This rule could be violated, specially if X includes variables that are not fully exogenous, and have a correlation with the treatment or outcome. This is what they call **bad controls**. The authors also show the sensibility of DML to the inclusion of bad controls, and compare the limited benefits of DML over Lasso estimations. In this regard, they are able to state that the usefulness of DML method for automated confounder selection is quite limited, and that, in general, the inclusion of bad controls is happens frequently, as these methods are used often. Therefore, the authors consider that ultimately, there **needs** to be a theoretical justification for the inclusion of covariates (an explanation of its exogeneity), and that the use of a simpler and smaller model would be preferable in high-dimensional settings.

Cinelli, Forney and Pearl (2022) is of crucial importance to researchers and students because it warns us about a typical mistake made in causal inference, which is not having a structural knowledge of how the covariates affect, or are affected by, the treatment and/or outcome. In this regard, for example, it is stated that "one should be cautious of the general recommendation (...) of conditioning on all pre-treatment predictors of the treatment assignment".

4. What would be one or two specific and valuable next steps to move forward on this question?

A valuable next step would involve trying to replicate documented studies on causal effects that used Lasso or DML, but with a smaller set of covariates that have a theoretical justification, instead of "automatizing" this process. We could then compare the results of both selection methods, in terms of the magnitude of the treatment effect. This would not only help to have a better knowledge on the causal effects that these documented studies tried to identify, but also support the ideas of Louw and Caspe (2022) and Cinelli, Forney and Pearl (2022). 

