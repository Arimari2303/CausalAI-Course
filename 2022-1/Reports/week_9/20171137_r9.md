## Report 9
### Lecture: Double/debiased machine learning for treatment and structural parameters
### Author: Victoria Olivera (20171137)

*	What is the research question of the article?

In this article, the research question is how to solve the classic semi-parametric problem of inference on a low-dimensional parameter $\theta_0$ in the presence of high-dimensional nuisance parameters $\eta_0$ using debiased machine learning (DML) methods. 

*	What are the strengths and weaknesses of the paper’s approach to answering that question?

Regarding the strengths, first, the authors show the benefits of using DML models instead ML methods. If we use ML methods regularization bias and overfitting in estimating $\eta_0$ cause a heavy bias in estimators of $\theta_0$ that are obtained by naively plugging ML estimators of $\eta_0$ into estimating equations for $\theta_0$. The DML methods removed the impact of regularization bias and overfitting on estimation of the parameter of interest $\theta_0$ using two instruments: Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate $\theta_0$ and cross-fitting, which provides an efficient form of data-splitting. Second, the DML methods allow the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. This last situation is due to the DML theory relying on only weak theoretical requirements. Third, in empirical applications no matter which ML method you use because the robustness of the results to the different methods is implied by the theory assuming that all of the employed methods are able to deliver sufficiently high-quality approximations to the underlying nuisance functions.

Regarding the weakness, in empirical applications, the incorporation of uncertainty due to sample splitting using the median method increases the standard errors relative to a baseline that does not account for this uncertainty.

*	How does this document advance knowledge about the question, that is, what is the contribution? (If you can't find any contributions, ask yourself why the editor and referees decided to publish the article)

The main article’s contribution is to offer a general and simple procedure (DML) for estimating and performing inference on $\theta_0$ that is formally valid in highly complex settings, like the entropy of the parameter space for the nuisance parameters is increasing with the sample size.

*	What would be one or two valuable and specific next steps to move forward on this question?

The next step to move forward is that the researchers could use other methods instead of the median method to reduce the standard errors. 
