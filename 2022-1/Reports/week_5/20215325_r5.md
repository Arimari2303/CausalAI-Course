Cinelli, Forney and Pearl's article focuses on the problem of "bad controls" in regression models, the question it seeks to answer is: How to provide a simple and concise visual summary of these criteria? through illustrative examples used by practicing analysts? .In HÃ¼nermund, Louw, and Caspi's article focusing on how machine learning methodology can be better than other forms of regression, the research question of this article is how machine learning provides a better way to regress considering the bias of the variables in the models?

The strengths of the Cinelli, Forney, and Pearl article is that it tells us that the idea that adding more variables to a model is not always a good thing, describe the causal diagrams (the mediators, common causes, and common effects), then use this tool to make illustrative models: bad, good and neutral, also explain the "bias", that is, the direction of the causality of the variables and the concept of "back door path" anda overcontrol bias that could make a bad control in the Models; the weakness of this document is that it does not show an empirical example of at least one issue like multiple controls or beyond fit.

The strengths of the article by Hunermund, Louw and Caspi is that they show a comparative estimation of matching learning with other methods, highlighting advantage factors such as detection of confounders, direction of bias and they also use an empirical example to demonstrate it.
The contribution of Cinelli, Forney and Pearl is that it summarizes everything that must be taken into account before studying causality, it describes several concepts so that the researcher gives a reference on how to intervene in his model.
Hunermund, Louw and Caspi's contribution is that they explain how correspondence learning can be used in a practical and simple way to solve many problems that other methods cannot solve.
It would be interesting to explain in which branch of the social sciences it is more reliable to apply Matching learning.