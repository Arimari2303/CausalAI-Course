{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33d7067",
   "metadata": {},
   "source": [
    "# 1.Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Pkg; Pkg.add(\"DataStructures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ece2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, \n",
    "DataStructures, NamedArrays, PrettyTables, StatsModels, Combinatorics, CSV, DelimitedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b02eaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10824.0 0.0 … 1.0 0.0; 10635.0 2.0 … 0.0 0.0; … ; 10691.0 0.0 … 0.0 0.0; 10677.0 5.0 … 1.0 0.0], AbstractString[\"abdt\" \"tg\" … \"husd\" \"muld\"])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat, head = readdlm(\"../../data/penn_jae.dat\",header=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9766e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>abdt</th><th>tg</th><th>inuidur1</th><th>inuidur2</th><th>female</th><th>black</th><th>hispanic</th><th>othrace</th><th>dep</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>13,913 rows × 23 columns (omitted printing of 14 columns)</p><tr><th>1</th><td>10824.0</td><td>0.0</td><td>18.0</td><td>18.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>2</th><td>10635.0</td><td>2.0</td><td>7.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>10551.0</td><td>5.0</td><td>18.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>10824.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>10747.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>10544.0</td><td>6.0</td><td>7.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>10845.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>10670.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>9</th><td>10768.0</td><td>3.0</td><td>28.0</td><td>11.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>10754.0</td><td>2.0</td><td>20.0</td><td>20.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>10712.0</td><td>3.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>12</th><td>10607.0</td><td>4.0</td><td>9.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>10831.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>14</th><td>10845.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>10831.0</td><td>0.0</td><td>9.0</td><td>9.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>16</th><td>10551.0</td><td>3.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>10859.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>18</th><td>10740.0</td><td>1.0</td><td>15.0</td><td>15.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>19</th><td>10537.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>10663.0</td><td>6.0</td><td>26.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>10656.0</td><td>5.0</td><td>30.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>22</th><td>10628.0</td><td>2.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>10516.0</td><td>0.0</td><td>15.0</td><td>15.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>10803.0</td><td>2.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>10663.0</td><td>0.0</td><td>28.0</td><td>11.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>10747.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>27</th><td>10551.0</td><td>4.0</td><td>22.0</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>28</th><td>10635.0</td><td>2.0</td><td>17.0</td><td>10.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>10761.0</td><td>2.0</td><td>13.0</td><td>13.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>10586.0</td><td>1.0</td><td>8.0</td><td>8.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824.0 & 0.0 & 18.0 & 18.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t2 & 10635.0 & 2.0 & 7.0 & 3.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 10551.0 & 5.0 & 18.0 & 6.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 10824.0 & 0.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 10747.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 10544.0 & 6.0 & 7.0 & 7.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 10845.0 & 1.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 10670.0 & 3.0 & 3.0 & 3.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t9 & 10768.0 & 3.0 & 28.0 & 11.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 10754.0 & 2.0 & 20.0 & 20.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 10712.0 & 3.0 & 6.0 & 6.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t12 & 10607.0 & 4.0 & 9.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 10831.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t14 & 10845.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 10831.0 & 0.0 & 9.0 & 9.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t16 & 10551.0 & 3.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 10859.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t18 & 10740.0 & 1.0 & 15.0 & 15.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t19 & 10537.0 & 1.0 & 1.0 & 1.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 10663.0 & 6.0 & 26.0 & 26.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 10656.0 & 5.0 & 30.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t22 & 10628.0 & 2.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 10516.0 & 0.0 & 15.0 & 15.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 10803.0 & 2.0 & 3.0 & 3.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 10663.0 & 0.0 & 28.0 & 11.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 10747.0 & 0.0 & 12.0 & 12.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t27 & 10551.0 & 4.0 & 22.0 & 22.0 & 1.0 & 0.0 & 1.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t28 & 10635.0 & 2.0 & 17.0 & 10.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 10761.0 & 2.0 & 13.0 & 13.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 10586.0 & 1.0 & 8.0 & 8.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m13913×23 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m abdt    \u001b[0m\u001b[1m tg      \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female  \u001b[0m\u001b[1m black   \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m oth\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Flo\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │ 10824.0      0.0      18.0      18.0      0.0      0.0       0.0      ⋯\n",
       "     2 │ 10635.0      2.0       7.0       3.0      0.0      0.0       0.0\n",
       "     3 │ 10551.0      5.0      18.0       6.0      1.0      0.0       0.0\n",
       "     4 │ 10824.0      0.0       1.0       1.0      0.0      0.0       0.0\n",
       "     5 │ 10747.0      0.0      27.0      27.0      0.0      0.0       0.0      ⋯\n",
       "     6 │ 10544.0      6.0       7.0       7.0      0.0      0.0       0.0\n",
       "     7 │ 10845.0      1.0       1.0       1.0      0.0      0.0       0.0\n",
       "     8 │ 10670.0      3.0       3.0       3.0      1.0      0.0       0.0\n",
       "     9 │ 10768.0      3.0      28.0      11.0      1.0      0.0       0.0      ⋯\n",
       "    10 │ 10754.0      2.0      20.0      20.0      1.0      0.0       0.0\n",
       "    11 │ 10712.0      3.0       6.0       6.0      0.0      0.0       0.0\n",
       "   ⋮   │    ⋮        ⋮        ⋮         ⋮         ⋮        ⋮        ⋮          ⋱\n",
       " 13904 │ 10747.0      3.0      15.0      15.0      1.0      0.0       1.0\n",
       " 13905 │ 10628.0      4.0      10.0      10.0      0.0      0.0       1.0      ⋯\n",
       " 13906 │ 10523.0      4.0       4.0       4.0      0.0      0.0       1.0\n",
       " 13907 │ 10558.0      0.0       9.0       9.0      0.0      0.0       0.0\n",
       " 13908 │ 10621.0      1.0       1.0       1.0      0.0      0.0       0.0\n",
       " 13909 │ 10831.0      5.0      27.0      27.0      0.0      0.0       0.0      ⋯\n",
       " 13910 │ 10677.0      2.0       4.0       4.0      1.0      0.0       0.0\n",
       " 13911 │ 10817.0      4.0       4.0       4.0      0.0      0.0       0.0\n",
       " 13912 │ 10691.0      0.0      27.0      27.0      0.0      0.0       0.0\n",
       " 13913 │ 10677.0      5.0      25.0      25.0      0.0      0.0       0.0      ⋯\n",
       "\u001b[36m                                               16 columns and 13892 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Penn = DataFrame(mat, vec(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "751f21ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>23 rows × 7 columns</p><tr><th>1</th><td>abdt</td><td>10695.4</td><td>10404.0</td><td>10698.0</td><td>10880.0</td><td>0</td><td>Float64</td></tr><tr><th>2</th><td>T4</td><td>0.342224</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>inuidur1</td><td>13.053</td><td>1.0</td><td>11.0</td><td>52.0</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>inuidur2</td><td>12.2812</td><td>0.0</td><td>10.0</td><td>52.0</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>female</td><td>0.404001</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>black</td><td>0.121985</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>hispanic</td><td>0.0325554</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>othrace</td><td>0.00725632</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>dep</td><td></td><td>0.0</td><td></td><td>2.0</td><td>0</td><td>CategoricalValue{Float64, UInt32}</td></tr><tr><th>10</th><td>q1</td><td>0.0127476</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>q2</td><td>0.203765</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>12</th><td>q3</td><td>0.235536</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>13</th><td>q4</td><td>0.225927</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>14</th><td>q5</td><td>0.25907</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>15</th><td>q6</td><td>0.0629535</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>16</th><td>recall</td><td>0.110414</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>17</th><td>agelt35</td><td>0.545009</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>18</th><td>agegt54</td><td>0.109433</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>19</th><td>durable</td><td>0.148068</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>20</th><td>nondurable</td><td>0.109237</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>21</th><td>lusd</td><td>0.261032</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>22</th><td>husd</td><td>0.21867</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>23</th><td>muld</td><td>0.444205</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & abdt & 10695.4 & 10404.0 & 10698.0 & 10880.0 & 0 & Float64 \\\\\n",
       "\t2 & T4 & 0.342224 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t3 & inuidur1 & 13.053 & 1.0 & 11.0 & 52.0 & 0 & Float64 \\\\\n",
       "\t4 & inuidur2 & 12.2812 & 0.0 & 10.0 & 52.0 & 0 & Float64 \\\\\n",
       "\t5 & female & 0.404001 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t6 & black & 0.121985 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t7 & hispanic & 0.0325554 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t8 & othrace & 0.00725632 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t9 & dep &  & 0.0 &  & 2.0 & 0 & CategoricalValue\\{Float64, UInt32\\} \\\\\n",
       "\t10 & q1 & 0.0127476 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t11 & q2 & 0.203765 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t12 & q3 & 0.235536 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t13 & q4 & 0.225927 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t14 & q5 & 0.25907 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t15 & q6 & 0.0629535 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t16 & recall & 0.110414 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t17 & agelt35 & 0.545009 & 0.0 & 1.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t18 & agegt54 & 0.109433 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t19 & durable & 0.148068 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t20 & nondurable & 0.109237 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t21 & lusd & 0.261032 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t22 & husd & 0.21867 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t23 & muld & 0.444205 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m23×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable   \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype    \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol     \u001b[0m\u001b[90m Union…     \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Union…  \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType  \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ abdt        10695.4     10404.0  10698.0  10880.0         0  Float64    ⋯\n",
       "   2 │ T4          0.342224    0.0      0.0      1.0             0  Float64\n",
       "   3 │ inuidur1    13.053      1.0      11.0     52.0            0  Float64\n",
       "   4 │ inuidur2    12.2812     0.0      10.0     52.0            0  Float64\n",
       "   5 │ female      0.404001    0.0      0.0      1.0             0  Float64    ⋯\n",
       "   6 │ black       0.121985    0.0      0.0      1.0             0  Float64\n",
       "   7 │ hispanic    0.0325554   0.0      0.0      1.0             0  Float64\n",
       "   8 │ othrace     0.00725632  0.0      0.0      1.0             0  Float64\n",
       "   9 │ dep        \u001b[90m            \u001b[0m 0.0     \u001b[90m         \u001b[0m 2.0             0  Categorica ⋯\n",
       "  10 │ q1          0.0127476   0.0      0.0      1.0             0  Float64\n",
       "  11 │ q2          0.203765    0.0      0.0      1.0             0  Float64\n",
       "  ⋮  │     ⋮           ⋮          ⋮        ⋮        ⋮        ⋮                 ⋱\n",
       "  14 │ q5          0.25907     0.0      0.0      1.0             0  Float64\n",
       "  15 │ q6          0.0629535   0.0      0.0      1.0             0  Float64    ⋯\n",
       "  16 │ recall      0.110414    0.0      0.0      1.0             0  Float64\n",
       "  17 │ agelt35     0.545009    0.0      1.0      1.0             0  Float64\n",
       "  18 │ agegt54     0.109433    0.0      0.0      1.0             0  Float64\n",
       "  19 │ durable     0.148068    0.0      0.0      1.0             0  Float64    ⋯\n",
       "  20 │ nondurable  0.109237    0.0      0.0      1.0             0  Float64\n",
       "  21 │ lusd        0.261032    0.0      0.0      1.0             0  Float64\n",
       "  22 │ husd        0.21867     0.0      0.0      1.0             0  Float64\n",
       "  23 │ muld        0.444205    0.0      0.0      1.0             0  Float64    ⋯\n",
       "\u001b[36m                                                     1 column and 2 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter control group and just treatment group number 4\n",
    "\n",
    "Penn = filter(row -> row[:tg] in [4,0], Penn)\n",
    "replace!(Penn.tg, 4 => 1)\n",
    "rename!(Penn, \"tg\" => \"T4\")\n",
    "Penn[!,:dep] = categorical(Penn[!,:dep])\n",
    "describe(Penn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9e5fde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>abdt</th><th>T4</th><th>inuidur1</th><th>inuidur2</th><th>female</th><th>black</th><th>hispanic</th><th>othrace</th><th>dep</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Cat…</th></tr></thead><tbody><p>5,099 rows × 23 columns (omitted printing of 14 columns)</p><tr><th>1</th><td>10824.0</td><td>0.0</td><td>18.0</td><td>18.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>2</th><td>10824.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>10747.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>10607.0</td><td>1.0</td><td>9.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>10831.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>6</th><td>10845.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>10831.0</td><td>0.0</td><td>9.0</td><td>9.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>8</th><td>10859.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>9</th><td>10516.0</td><td>0.0</td><td>15.0</td><td>15.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>10663.0</td><td>0.0</td><td>28.0</td><td>11.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>10747.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>12</th><td>10551.0</td><td>1.0</td><td>22.0</td><td>22.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>13</th><td>10768.0</td><td>0.0</td><td>18.0</td><td>18.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>10537.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>15</th><td>10600.0</td><td>1.0</td><td>7.0</td><td>7.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>10866.0</td><td>0.0</td><td>18.0</td><td>18.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>10572.0</td><td>0.0</td><td>14.0</td><td>14.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>18</th><td>10663.0</td><td>0.0</td><td>5.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>10789.0</td><td>0.0</td><td>9.0</td><td>9.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>10768.0</td><td>0.0</td><td>3.0</td><td>3.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>10649.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>22</th><td>10670.0</td><td>1.0</td><td>27.0</td><td>27.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>23</th><td>10796.0</td><td>0.0</td><td>10.0</td><td>10.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>10558.0</td><td>0.0</td><td>25.0</td><td>25.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>25</th><td>10831.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>10810.0</td><td>1.0</td><td>3.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>10551.0</td><td>1.0</td><td>13.0</td><td>13.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>28</th><td>10796.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>10719.0</td><td>0.0</td><td>27.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>10726.0</td><td>1.0</td><td>14.0</td><td>14.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& abdt & T4 & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Cat… & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824.0 & 0.0 & 18.0 & 18.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t2 & 10824.0 & 0.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 10747.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 10607.0 & 1.0 & 9.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 10831.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t6 & 10845.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 10831.0 & 0.0 & 9.0 & 9.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t8 & 10859.0 & 0.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t9 & 10516.0 & 0.0 & 15.0 & 15.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 10663.0 & 0.0 & 28.0 & 11.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t11 & 10747.0 & 0.0 & 12.0 & 12.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t12 & 10551.0 & 1.0 & 22.0 & 22.0 & 1.0 & 0.0 & 1.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t13 & 10768.0 & 0.0 & 18.0 & 18.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 10537.0 & 0.0 & 1.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t15 & 10600.0 & 1.0 & 7.0 & 7.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 10866.0 & 0.0 & 18.0 & 18.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 10572.0 & 0.0 & 14.0 & 14.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t18 & 10663.0 & 0.0 & 5.0 & 5.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t19 & 10789.0 & 0.0 & 9.0 & 9.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 10768.0 & 0.0 & 3.0 & 3.0 & 0.0 & 1.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 10649.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t22 & 10670.0 & 1.0 & 27.0 & 27.0 & 1.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t23 & 10796.0 & 0.0 & 10.0 & 10.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 10558.0 & 0.0 & 25.0 & 25.0 & 0.0 & 0.0 & 1.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t25 & 10831.0 & 1.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 10810.0 & 1.0 & 3.0 & 3.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 10551.0 & 1.0 & 13.0 & 13.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t28 & 10796.0 & 0.0 & 1.0 & 1.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 10719.0 & 0.0 & 27.0 & 27.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 10726.0 & 1.0 & 14.0 & 14.0 & 0.0 & 0.0 & 0.0 & 0.0 & 2.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5099×23 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m abdt    \u001b[0m\u001b[1m T4      \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female  \u001b[0m\u001b[1m black   \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m othr\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 10824.0      0.0      18.0      18.0      0.0      0.0       0.0       ⋯\n",
       "    2 │ 10824.0      0.0       1.0       1.0      0.0      0.0       0.0\n",
       "    3 │ 10747.0      0.0      27.0      27.0      0.0      0.0       0.0\n",
       "    4 │ 10607.0      1.0       9.0       9.0      0.0      0.0       0.0\n",
       "    5 │ 10831.0      0.0      27.0      27.0      0.0      0.0       0.0       ⋯\n",
       "    6 │ 10845.0      0.0      27.0      27.0      1.0      0.0       0.0\n",
       "    7 │ 10831.0      0.0       9.0       9.0      1.0      0.0       0.0\n",
       "    8 │ 10859.0      0.0      27.0      27.0      1.0      0.0       0.0\n",
       "    9 │ 10516.0      0.0      15.0      15.0      1.0      0.0       0.0       ⋯\n",
       "   10 │ 10663.0      0.0      28.0      11.0      1.0      0.0       0.0\n",
       "   11 │ 10747.0      0.0      12.0      12.0      1.0      0.0       0.0\n",
       "  ⋮   │    ⋮        ⋮        ⋮         ⋮         ⋮        ⋮        ⋮         ⋮ ⋱\n",
       " 5090 │ 10635.0      1.0      20.0      20.0      0.0      0.0       0.0\n",
       " 5091 │ 10859.0      0.0       1.0       1.0      1.0      0.0       0.0       ⋯\n",
       " 5092 │ 10796.0      0.0      23.0      23.0      0.0      1.0       0.0\n",
       " 5093 │ 10740.0      1.0      13.0      13.0      1.0      1.0       0.0\n",
       " 5094 │ 10845.0      0.0       6.0       6.0      1.0      0.0       0.0\n",
       " 5095 │ 10628.0      1.0      10.0      10.0      0.0      0.0       1.0       ⋯\n",
       " 5096 │ 10523.0      1.0       4.0       4.0      0.0      0.0       1.0\n",
       " 5097 │ 10558.0      0.0       9.0       9.0      0.0      0.0       0.0\n",
       " 5098 │ 10817.0      1.0       4.0       4.0      0.0      0.0       0.0\n",
       " 5099 │ 10691.0      0.0      27.0      27.0      0.0      0.0       0.0       ⋯\n",
       "\u001b[36m                                                16 columns and 5078 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Penn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e847889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       ":(log(inuidur1)) ~ 1 + T4 + female + black + othrace + dep + q2 + q3 + q4 + q5 + q6 + agelt35 + agegt54 + durable + lusd + husd + female & black\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────────\n",
       "                      Coef.  Std. Error      t  Pr(>|t|)    Lower 95%    Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)      2.16747      0.159179   13.62    <1e-40   1.85541      2.47953\n",
       "T4              -0.0706678    0.0354665  -1.99    0.0464  -0.140197    -0.00113809\n",
       "female           0.145419     0.0372302   3.91    <1e-04   0.0724319    0.218406\n",
       "black           -0.230081     0.068888   -3.34    0.0008  -0.365132    -0.0950312\n",
       "othrace         -0.473988     0.198379   -2.39    0.0169  -0.862897    -0.0850798\n",
       "dep: 1.0         0.0348823    0.0542454   0.64    0.5202  -0.0714622    0.141227\n",
       "dep: 2.0         0.100883     0.0469697   2.15    0.0318   0.00880188   0.192963\n",
       "q2               0.0761343    0.156818    0.49    0.6273  -0.231297     0.383566\n",
       "q3              -0.0370795    0.156464   -0.24    0.8127  -0.343817     0.269658\n",
       "q4              -0.0546722    0.156544   -0.35    0.7269  -0.361565     0.252221\n",
       "q5              -0.142148     0.155878   -0.91    0.3619  -0.447735     0.163439\n",
       "q6               0.00406777   0.166439    0.02    0.9805  -0.322224     0.330359\n",
       "agelt35         -0.16185      0.0369666  -4.38    <1e-04  -0.234321    -0.0893797\n",
       "agegt54          0.230626     0.0591691   3.90    <1e-04   0.114629     0.346623\n",
       "durable          0.12701      0.0481417   2.64    0.0084   0.0326313    0.221388\n",
       "lusd            -0.175922     0.04098    -4.29    <1e-04  -0.256261    -0.0955839\n",
       "husd            -0.1066       0.0449139  -2.37    0.0177  -0.19465     -0.018549\n",
       "female & black  -0.150908     0.104361   -1.45    0.1482  -0.355501     0.0536844\n",
       "──────────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula1 =@formula( log(inuidur1)~ T4+ (female+black+othrace+dep+q2+q3+q4+q5+q6+agelt35+agegt54+durable+lusd+husd))\n",
    "ols1 = lm(formula1, Penn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44c7e4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052975562178876896"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_T4 = GLM.coeftable(ols1).cols[2][2]\n",
    "std_female = GLM.coeftable(ols1).cols[2][3]\n",
    "std_black = GLM.coeftable(ols1).cols[2][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0b875d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boot_fn1 (generic function with 1 method)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function boot_fn1(data,index)\n",
    "            formula1 =@formula( log(inuidur1)~ T4+ (female+black+othrace+dep+q2+q3+q4+q5+q6+agelt35+agegt54+durable+lusd+husd))\n",
    "            ols1 = lm(formula1, Penn[index,:])\n",
    "            coef_T4 = GLM.coeftable(ols1).cols[1][2]\n",
    "            coef_female = GLM.coeftable(ols1).cols[1][3]\n",
    "            coef_black = GLM.coeftable(ols1).cols[1][4]\n",
    "            return [coef_T4, coef_female, coef_black]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5e37e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boot_1 (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function boot_1(data,func,R)\n",
    "            Random.seed!(1)\n",
    "            n = size(Penn)[1]\n",
    "            coef_T4 = []\n",
    "            coef_female = []\n",
    "            coef_black = []\n",
    "            for i in 1:R\n",
    "                append!(coef_T4,func(data,sample([1:5099 ;], n, replace = true))[1])\n",
    "                append!(coef_female,func(data,sample([1:5099;], n, replace = true))[2])\n",
    "                append!(coef_black,func(data,sample([1:5099;], n, replace = true))[3])\n",
    "            end\n",
    "        table = NamedArray(zeros(3, 3))\n",
    "\n",
    "        table[1,2] = mean(coef_T4)\n",
    "        table[1,3] = std(coef_T4, corrected=true)\n",
    "        table[2,2] = mean(coef_female)\n",
    "        table[2,3] = std(coef_female, corrected=true)\n",
    "        table[3,2] = mean(coef_black)\n",
    "        table[3,3] = std(coef_black, corrected=true)\n",
    "    \n",
    "        T = DataFrame(table, [ :\"Variable\", :\"Mean Coefficient (boostrap)\", :\"Standar error Coefficient (boostrap)\"]) \n",
    "        T[!,:Variable] = string.(T[!,:Variable]) \n",
    "\n",
    "        T[1,1] = \"Treatment (T4)\"\n",
    "        T[2,1] = \"Female\"\n",
    "        T[3,1] = \"Black\"\n",
    "        \n",
    "        bootstrap_statistics = Dict{String,Any}(\"Table\" => T, \"Treatment (T4)\" => coef_T4, \"Female\" => coef_female,\n",
    "        \"Black\" => coef_black)\n",
    "    return bootstrap_statistics\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42ecb555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Variable</th><th>Mean Coefficient (boostrap)</th><th>Standar error Coefficient (boostrap)</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3 rows × 3 columns</p><tr><th>1</th><td>Treatment (T4)</td><td>-0.0718697</td><td>0.0355158</td></tr><tr><th>2</th><td>Female</td><td>0.12608</td><td>0.0344085</td></tr><tr><th>3</th><td>Black</td><td>-0.295361</td><td>0.0609133</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Variable & Mean Coefficient (boostrap) & Standar error Coefficient (boostrap)\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Treatment (T4) & -0.0718697 & 0.0355158 \\\\\n",
       "\t2 & Female & 0.12608 & 0.0344085 \\\\\n",
       "\t3 & Black & -0.295361 & 0.0609133 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Variable       \u001b[0m\u001b[1m Mean Coefficient (boostrap) \u001b[0m\u001b[1m Standar error Coefficient \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String         \u001b[0m\u001b[90m Float64                     \u001b[0m\u001b[90m Float64                   \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ Treatment (T4)                   -0.0718697                             ⋯\n",
       "   2 │ Female                            0.12608\n",
       "   3 │ Black                            -0.295361\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_1(Penn,boot_fn1,1000)[\"Table\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd507619",
   "metadata": {},
   "source": [
    "# 2. Comparative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65fcdc8",
   "metadata": {},
   "source": [
    "**Basic Model** \\\n",
    "lnw ~ female + female : (widowed + divorced + separated + nevermarried +\n",
    "hsd08 + hsd911 + hsg + cg + ad + mw + so + we + exp1 + exp2 + exp3\n",
    "\n",
    "**Flexible  Model** (revisar problemas de muchas variables) \\\n",
    "lnw ~ female + female : (widowed + divorced + separated + nevermarried +\n",
    "hsd08 + hsd911 + hsg + cg + ad + mw + so + we + exp1 + exp2 + exp3) + (widowed + divorced + separated + nevermarried + hsd08 + hsd911 + hsg + cg + ad + mw + so +we + exp1 + exp2 + exp3) ^ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be653f8",
   "metadata": {},
   "source": [
    "**Models:**\\\n",
    "\\\n",
    "*Lineal Models*\n",
    "- OLS\n",
    "- Lasso HDM\n",
    "- Lasso CV\n",
    "- Elastic Net - CV\n",
    "- Ridge Lasso - CV\n",
    "\n",
    "\n",
    "\n",
    "*No Lineal Models*\n",
    "- Tree regression\n",
    "- Pruned tree regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861c993",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3a8a7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45e1bb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23-element Vector{String}:\n",
       " \"year\"\n",
       " \"lnw\"\n",
       " \"female\"\n",
       " \"widowed\"\n",
       " \"divorced\"\n",
       " \"separated\"\n",
       " \"nevermarried\"\n",
       " \"hsd08\"\n",
       " \"hsd911\"\n",
       " \"hsg\"\n",
       " \"cg\"\n",
       " \"ad\"\n",
       " \"mw\"\n",
       " \"so\"\n",
       " \"we\"\n",
       " \"exp1\"\n",
       " \"exp2\"\n",
       " \"exp3\"\n",
       " \"exp4\"\n",
       " \"weight\"\n",
       " \"married\"\n",
       " \"ne\"\n",
       " \"sc\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cps = load(\"../../data/cps2012.RData\")\n",
    "data=cps[\"data\"]\n",
    "names(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabc0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d4c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51658594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda99cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35d335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61afea1e",
   "metadata": {},
   "source": [
    "# 3.Tree regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3653e0f0",
   "metadata": {},
   "source": [
    "Usually, to make regressions we assume a linear relation between variables. In the case where clusters might be found in the data, a linear regression is not the best way to estimate a prediction model. The best way is to use a Tree regression since it captures non-linear relations between the Y and the X regressors. For instance, a regression tree allows us to make a prediction using continuous or categorical variables. However, a regression tree always tries to predict a continuous value. \\\n",
    "The main concept of regression tree (also classifier tree) is to split the data in a binary criterion until it reaches pure leaf. Finally, each leaf represents a relevant cluster in our dataset. This allows to predict a in which group a new observation in the data corresponds by following the conditions node by node. \\\n",
    "The first step consists in determine under which value we split the first node. Therefore, we need to find the best splitting condition. For this step the computer tests each possible value to split the data and propose a set of candidates. In a scenario with multiple covariates, the algorithm evaluates each covariate one at time, and for each covariate estimates the proper split value by choosing the one with lowest sum squared errors. The variable that goes in the first node is the one with the lowest sum squared errors. This process repeats for each node. \\\n",
    "This step repeats for each possible split. However, the number of final leaves will depend on if it is needed to do an extra split in each leaf. This process can result in an overfitting of the data and the model can´t be generalize. To solve this, we have to prune the tree by setting penalization parameters on the impurities of the leaf.\\\n",
    "First, we have to determine the optimal complexity of the tree. To do this we set the algorithm to prune or “cut” the leaf with a relatively small alpha. The smallest alphas are pruned first. We set an algorithm that returns the effective alphas and the corresponding total leaf impurities at each step of the pruning process. Larger alphas mean more of the tree is pruned, which increases the total impurity of its leaves.\\\n",
    "Next, we make a cross validation process for al the alphas proposed and calculate the accuracy mean for each alpha. The optimal alpha for our tree would be the one with the lowest mean accuracy rate. \\\n",
    "Finally. We set that value of alpha in the DecisionTreeRegressor function in Python to get our optimal depth and number of leaves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
