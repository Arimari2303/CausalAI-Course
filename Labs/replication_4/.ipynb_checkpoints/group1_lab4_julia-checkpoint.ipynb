{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Orthogonal Learning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Design 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"StatsPlots\")\n",
    "Pkg.add(\"GraphRecipes\")\n",
    "Pkg.add(\"Gadfly\")\n",
    "Pkg.add(\"Conda\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"DataTables\")\n",
    "Pkg.add(\"TypedTables\")\n",
    "Pkg.add(\"MacroTools\")\n",
    "Pkg.add(\"TexTables\")\n",
    "Pkg.add(\"PlotlyJS\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"FileIO\")\n",
    "Pkg.add(\"ClinicalTrialUtilities\")\n",
    "Pkg.add(\"KernelDensity\")\n",
    "Conda.pip_interop(true)\n",
    "Conda.pip(\"install\", \"webio_jupyter_extension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {
      "application/vnd.webio.node+json": {
       "kernelId": "4174c721-888d-4130-8fce-39b2da4844d6"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Pkg\n",
    "using Random\n",
    "using GLM, StatsModels\n",
    "using DataTables\n",
    "using DelimitedFiles, DataFrames, Lasso\n",
    "using FilePaths\n",
    "using StatsModels, Combinatorics\n",
    "using CategoricalArrays\n",
    "using StatsBase, Statistics\n",
    "using TypedTables\n",
    "using MacroTools\n",
    "using NamedArrays\n",
    "using PrettyTables # Dataframe or Datatable to latex\n",
    "using TexTables # pretty regression table and tex outcome\n",
    "using Plots\n",
    "using Conda\n",
    "using Images, FileIO\n",
    "using ClinicalTrialUtilities\n",
    "using PlotlyJS\n",
    "using KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../Julia_Notebooks/hdmjl/hdmjl.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "Random.seed!(23)\n",
    "B = 100\n",
    "Naive = zeros(B)\n",
    "Orthogonal = zeros(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:red\">Error</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching DataFrame(::Vector{Vector{T} where T}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::AbstractVector{var\"#s18\"} where var\"#s18\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:242\n\u001b[0m  DataFrame(::AbstractVector{var\"#s19\"} where var\"#s19\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{var\"#s18\"} where var\"#s18\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:249\n\u001b[0m  DataFrame(::AbstractVector{T} where T, \u001b[91m::AbstractVector{var\"#s20\"} where var\"#s20\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:237\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DataFrame(::Vector{Vector{T} where T}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::AbstractVector{var\"#s18\"} where var\"#s18\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:242\n\u001b[0m  DataFrame(::AbstractVector{var\"#s19\"} where var\"#s19\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{var\"#s18\"} where var\"#s18\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:249\n\u001b[0m  DataFrame(::AbstractVector{T} where T, \u001b[91m::AbstractVector{var\"#s20\"} where var\"#s20\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:237\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] rlasso(self::rlasso_arg)",
      "   @ Main C:\\Users\\JARVIS\\Documents\\GitHub\\ECO224\\Labs\\Julia_Notebooks\\hdmjl\\hdmjl.jl:668",
      " [2] top-level scope",
      "   @ In[4]:33",
      " [3] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "p = 100\n",
    "beta =  reshape(( 1 ./ (1:p).^ 2 ),100,1)\n",
    "gamma = reshape(( 1 ./ (1:p).^ 2 ),100,1)\n",
    "\n",
    "# mean = 0\n",
    "sd = 1\n",
    "X = randn(( n, p ))\n",
    "\n",
    "D = ( X * gamma ) + reshape(randn(n),n, 1)/4 \n",
    "\n",
    "# DGP \n",
    "Y = D + ( X * beta ) + reshape(randn( n ), n, 1 )\n",
    "\n",
    "\n",
    "D = convert(DataFrame,D)\n",
    "rename!(D,:x1 => :D)\n",
    "X = convert(DataFrame,X)\n",
    "Y =  convert(DataFrame,Y)\n",
    "rename!(Y,:x1 => :Y)\n",
    "\n",
    "DX = hcat( D , X)\n",
    "YD = hcat( Y , D)\n",
    "\n",
    "# Y =  convert(DataFrame,Y)\n",
    "# rename!(Y,:x1 => :Y)\n",
    "# D = convert(DataFrame,D)\n",
    "# rename!(D,:x1 => :D)\n",
    "# X = convert(DataFrame,X)\n",
    "\n",
    "r_lasso_estimation = rlasso_arg( DX , Y , nothing, true, true, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true ) # Regress main equation by lasso\n",
    "coef_array = rlasso(r_lasso_estimation)[\"beta\"][2:end,2]\n",
    "SX_IDs  = findall(x-> x != 0,coef_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:red\">Son dataframes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame, DataFrame)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(Y),typeof(DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlasso_arg(100×101 DataFrame. Omitted printing of 96 columns\n",
       "│ Row │ D          │ x1         │ x2        │ x3        │ x4        │\n",
       "│     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼────────────┼────────────┼───────────┼───────────┼───────────┤\n",
       "│ 1   │ -0.353761  │ 0.289581   │ -0.953054 │ 1.83341   │ -0.745618 │\n",
       "│ 2   │ -0.371052  │ -0.638607  │ 0.685025  │ 1.94144   │ -0.677401 │\n",
       "│ 3   │ 0.701629   │ 0.443883   │ 1.62411   │ 1.05002   │ 0.934413  │\n",
       "│ 4   │ 1.76462    │ 1.87079    │ -0.164695 │ -1.37862  │ -0.227641 │\n",
       "│ 5   │ -0.233734  │ -0.115     │ -0.532952 │ 0.0655356 │ 0.65679   │\n",
       "│ 6   │ 0.92019    │ 0.870427   │ 0.415723  │ 1.95379   │ -0.904642 │\n",
       "│ 7   │ -1.49862   │ -1.81103   │ 0.500987  │ 0.591362  │ 0.656447  │\n",
       "│ 8   │ 0.593295   │ 0.0349133  │ 2.75274   │ -1.32453  │ -1.87789  │\n",
       "│ 9   │ -0.0302368 │ -0.302082  │ 0.738428  │ -0.335426 │ -2.14037  │\n",
       "│ 10  │ 1.52456    │ 1.53132    │ 0.313429  │ 0.0812106 │ 1.33983   │\n",
       "⋮\n",
       "│ 90  │ -1.98485   │ -1.48835   │ -1.78022  │ 1.62054   │ -0.877997 │\n",
       "│ 91  │ -0.287558  │ -0.0822858 │ -0.793089 │ 1.60646   │ 0.569351  │\n",
       "│ 92  │ 1.33056    │ 1.44607    │ -0.222036 │ 1.64546   │ 0.052624  │\n",
       "│ 93  │ -1.26135   │ -1.27926   │ 0.595329  │ -0.55304  │ -0.138636 │\n",
       "│ 94  │ 1.88879    │ 2.08699    │ 0.0458823 │ -1.07672  │ 1.082     │\n",
       "│ 95  │ 0.685234   │ 1.01871    │ -0.424743 │ -1.14035  │ -2.93772  │\n",
       "│ 96  │ 0.155868   │ 0.279289   │ 0.238598  │ 0.806803  │ 0.844372  │\n",
       "│ 97  │ -0.440967  │ -0.562027  │ 1.19072   │ -1.20291  │ 0.197127  │\n",
       "│ 98  │ 0.604421   │ -0.212596  │ 0.957243  │ 0.59556   │ 2.05231   │\n",
       "│ 99  │ 1.43312    │ 1.58174    │ -1.14457  │ 1.31459   │ -0.192523 │\n",
       "│ 100 │ 1.37132    │ 1.21945    │ 0.58132   │ 2.33122   │ 0.662079  │, 100×1 DataFrame\n",
       "│ Row │ Y           │\n",
       "│     │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼─────────────┤\n",
       "│ 1   │ 0.964047    │\n",
       "│ 2   │ -0.76799    │\n",
       "│ 3   │ 1.01629     │\n",
       "│ 4   │ 2.26623     │\n",
       "│ 5   │ -0.300384   │\n",
       "│ 6   │ 4.10377     │\n",
       "│ 7   │ -2.65812    │\n",
       "│ 8   │ 0.559845    │\n",
       "│ 9   │ -0.00894549 │\n",
       "│ 10  │ 1.78483     │\n",
       "⋮\n",
       "│ 90  │ -6.32958    │\n",
       "│ 91  │ -1.99941    │\n",
       "│ 92  │ -0.11696    │\n",
       "│ 93  │ -1.76051    │\n",
       "│ 94  │ 3.21993     │\n",
       "│ 95  │ 1.92371     │\n",
       "│ 96  │ 1.48214     │\n",
       "│ 97  │ -1.47271    │\n",
       "│ 98  │ 1.19597     │\n",
       "│ 99  │ 3.25901     │\n",
       "│ 100 │ 3.35931     │, nothing, true, true, true, false, false, nothing, 1.1, nothing, 5000, 15, 1.0000000000000003e-5, -Inf, true, Inf, true)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Esta parte sí corre\n",
    "r_lasso_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching DataFrame(::Vector{Vector{T} where T}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::AbstractVector{var\"#s18\"} where var\"#s18\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:242\n\u001b[0m  DataFrame(::AbstractVector{var\"#s19\"} where var\"#s19\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{var\"#s18\"} where var\"#s18\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:249\n\u001b[0m  DataFrame(::AbstractVector{T} where T, \u001b[91m::AbstractVector{var\"#s20\"} where var\"#s20\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:237\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DataFrame(::Vector{Vector{T} where T}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  DataFrame(::AbstractVector{var\"#s18\"} where var\"#s18\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{Symbol}\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:242\n\u001b[0m  DataFrame(::AbstractVector{var\"#s19\"} where var\"#s19\"<:(AbstractVector{T} where T), \u001b[91m::AbstractVector{var\"#s18\"} where var\"#s18\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:249\n\u001b[0m  DataFrame(::AbstractVector{T} where T, \u001b[91m::AbstractVector{var\"#s20\"} where var\"#s20\"<:AbstractString\u001b[39m; makeunique, copycols) at C:\\Users\\JARVIS\\.julia\\packages\\DataFrames\\GtZ1l\\src\\dataframe\\dataframe.jl:237\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] rlasso(self::rlasso_arg)",
      "   @ Main C:\\Users\\JARVIS\\Documents\\GitHub\\ECO224\\Labs\\Julia_Notebooks\\hdmjl\\hdmjl.jl:668",
      " [2] top-level scope",
      "   @ In[5]:34",
      " [3] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "for i in 1:B\n",
    "    n = 100\n",
    "    p = 100\n",
    "    beta =  reshape(( 1 ./ (1:p).^ 2 ),100,1)\n",
    "    gamma = reshape(( 1 ./ (1:p).^ 2 ),100,1)\n",
    "\n",
    "    # mean = 0\n",
    "    sd = 1\n",
    "    X = randn(( n, p ))\n",
    "\n",
    "    D = ( X * gamma ) + reshape(randn(n),n, 1)/4 \n",
    "\n",
    "    # DGP \n",
    "    Y = D + ( X * beta ) + reshape(randn( n ), n, 1 )\n",
    "\n",
    "\n",
    "    D = convert(DataFrame,D)\n",
    "    rename!(D,:x1 => :D)\n",
    "    X = convert(DataFrame,X)\n",
    "    Y =  convert(DataFrame,Y)\n",
    "    rename!(Y,:x1 => :Y)\n",
    "\n",
    "    DX = hcat( D , X)\n",
    "    YD = hcat( Y , D)\n",
    "\n",
    "    # Y =  convert(DataFrame,Y)\n",
    "    # rename!(Y,:x1 => :Y)\n",
    "    # D = convert(DataFrame,D)\n",
    "    # rename!(D,:x1 => :D)\n",
    "    # X = convert(DataFrame,X)\n",
    "\n",
    "    r_lasso_estimation = rlasso_arg( DX , Y , nothing, true, true, true, false, false, \n",
    "                        nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true ) # Regress main equation by lasso\n",
    "    coef_array = rlasso(r_lasso_estimation)[\"beta\"][2:end,2]\n",
    "    SX_IDs  = findall(x-> x != 0,coef_array)\n",
    "\n",
    "    # In case all X coefficients are zero, then regress Y on D\n",
    "    if sum(SX_IDs) == 0 \n",
    "        reg = lm( @formula(Y ~ D), YD )\n",
    "        Naive[i] = GLM.coeftable(reg).cols[1,1][2]\n",
    "\n",
    "    # Otherwise, then regress Y on X and D (but only in the selected coefficients)\n",
    "    elseif sum( SX_IDs ) > 0\n",
    "        X_D = hcat(Y, D, X[:, SX_IDs ],makeunique=true ) \n",
    "        rename!(X_D,:x1 => :Y)\n",
    "        rename!(X_D,:x1_1 => :D)\n",
    "        rename!(X_D,:x1_2 => :X)\n",
    "        reg = lm( @formula(Y ~ D+X),X_D )\n",
    "        Naive[ i ] = GLM.coeftable(reg).cols[1,1][2]\n",
    "    end\n",
    "    # In both cases we save D coefficient\n",
    "\n",
    "    # Regress residuals. \n",
    "    regY = rlasso_arg( X , Y , nothing, true, false, true, false, false, \n",
    "                        nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "    resY = rlasso(regY)[\"residuals\"]\n",
    "\n",
    "    regD = rlasso_arg( X , D , nothing, true, false, true, false, false, \n",
    "                        nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "    resD = rlasso(regD)[\"residuals\"]\n",
    "\n",
    "    eYeD = convert(DataFrame,hcat( resY , resD))\n",
    "    rename!(eYeD,:x1 => :resY)\n",
    "    rename!(eYeD,:x2 => :resD)\n",
    "\n",
    "    res_reg= lm( @formula(resY ~ resD), eYeD)\n",
    "    Orthogonal[ i ] = GLM.coeftable(reg).cols[1,1][2]\n",
    "        \n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Application: Heterogeneous Effect of Gender on Wage Using Double Lasso</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use US census data from the year 2012 to analyse the effect of gender and interaction effects of other variables with gender on wage jointly. The dependent variable is the logarithm of the wage, the target variable is female (in combination with other variables). All other variables denote some other socio-economic characteristics, e.g. marital status, education, and experience. For a detailed description of the variables we refer to the help page.\n",
    "\n",
    "This analysis allows a closer look how discrimination according to gender is related to other socio-economic variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, \n",
    "DataStructures, NamedArrays, PrettyTables, StatsModels, Combinatorics\n",
    "\n",
    "import CodecBzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing .Rdata file\n",
    "\n",
    "cps2012 = load(\"GitHub/ECO224/data/cps2012.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys(cps2012)   # get information from key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps2012 = cps2012[\"data\"]\n",
    "\n",
    "names(cps2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# couples variables combinations \n",
    "    combinations_upto(x, n) = Iterators.flatten(combinations(x, i) for i in 1:n)\n",
    "\n",
    "    # combinations without same couple\n",
    "    expand_exp(args, deg::ConstantTerm) =\n",
    "        tuple(((&)(terms...) for terms in combinations_upto(args, deg.n))...)\n",
    "\n",
    "    StatsModels.apply_schema(t::FunctionTerm{typeof(^)}, sch::StatsModels.Schema, ctx::Type) =\n",
    "        apply_schema.(expand_exp(t.args_parsed...), Ref(sch), ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model \n",
    "\n",
    "\n",
    "reg = @formula(lnw ~ -1 + female + female&(widowed + divorced + separated + nevermarried +\n",
    "hsd08 + hsd911 + hsg + cg + ad + mw + so + we + exp1 + exp2 + exp3) + (widowed +\n",
    "divorced + separated + nevermarried + hsd08 + hsd911 + hsg + cg + ad + mw + so +\n",
    "we + exp1 + exp2 + exp3)^2 )\n",
    "\n",
    "\n",
    "formula_basic = apply_schema(reg, schema(reg, cps2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefnames(formula_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = select(cps2012,:lnw)  # uptcome variable\n",
    "control = coefnames(formula_basic)[2]  # regresors control \n",
    "names_col = Symbol.(control)  # string to Symbol to create varaible's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StatsModels.modelmatrix(formula_basic,cps2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataFrame(X, names_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get index of constant columns   \n",
    "\n",
    "cons_column = []\n",
    "\n",
    "\n",
    "for i in 1:size(X,2)\n",
    "    if var(X[!,i]) == 0\n",
    "        append!(cons_column  , i)      \n",
    "    end       \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant columns \n",
    "\n",
    "names(X)[cons_column]\n",
    "select!(X, Not(names(X)[cons_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demean function\n",
    "function desv_mean(a)\n",
    "    a = Matrix(a)   # dataframe to matrix \n",
    "    A = mean(a, dims = 1)\n",
    "    M = zeros(Float64, size(X,1), size(X,2))\n",
    "    \n",
    "    for i in 1:size(a,2)\n",
    "          M[:,i] = a[:,i] .- A[i]\n",
    "    end\n",
    "    \n",
    "    return M\n",
    "end    \n",
    "\n",
    "\n",
    "# Matrix Model & demean\n",
    "\n",
    "X = DataFrame(desv_mean(X), names(X)) # Dataframe and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index to get columns that contains female\n",
    "\n",
    "index = []\n",
    "\n",
    "for i in 1:size(X,2)  \n",
    "        if contains( names(X)[i] , \"female\")\n",
    "            append!(index, i)\n",
    "        end  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables \n",
    "\n",
    "W = select(X, Not(names(X)[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDM package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = NamedArray(zeros(16, 2))\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in 1:length(index)\n",
    "\n",
    "j = j + 1\n",
    "    \n",
    "#first step\n",
    "D = select(X, names(X)[index[i]])\n",
    "    \n",
    "D_reg_0  = rlasso_arg( W, D, nothing, true, true, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "\n",
    "\n",
    "D_resid[!,j] = rlasso(D_reg_0)[\"residuals\"]\n",
    "\n",
    "#second step\n",
    "    \n",
    "# third step\n",
    "    \n",
    "#Lasso_HDM = lm(D_resid, Y_resid)\n",
    "\n",
    "#table[j,1] = GLM.coeftable(Lasso_HDM).cols[5][1]\n",
    "#table[j,2] = GLM.coeftable(Lasso_HDM).cols[6][1]\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Double Lasso - Testing the Convergence Hypothesis </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide an additional empirical example of partialling-out with Lasso to estimate the regression coefficient $\\beta$ in the high-dimensional linear regression model:\n",
    "\n",
    "$$ Y = \\beta_1 D + \\beta_2^{'}W + \\epsilon $$\n",
    "\n",
    "Specifically, we are interested in how the rates at which economies of different countries grow ($Y$) are related to the initial wealth levels in each country ($D$) controlling for country's institutional, educational, and other similar characteristics ($W$).\n",
    "\n",
    "The relationship is captured by $\\beta_1$, the speed of convergence/divergence, which measures the speed at which poor countries catch up ($\\beta_1$<0) or fall behind ($\\beta_2$>0) rich countries, after controlling for $W$ . Our inference question here is: do poor countries grow faster than rich countries, controlling for educational and other characteristics? In other words, is the speed of convergence negative: $\\beta_1$<0? This is the Convergence Hypothesis predicted by the Solow Growth Model. This is a structural economic model. Under some strong assumptions, that we won't state here, the predictive exercise we are doing here can be given causal interpretation.\n",
    "\n",
    "The outcome $Y$ is the realized annual growth rate of a country's wealth (Gross Domestic Product per capita). The target regressor ($D$) is the initial level of the country's wealth. The target parameter $\\beta_1$ is the speed of convergence, which measures the speed at which poor countries catch up with rich countries. The controls ($W$) include measures of education levels, quality of institutions, trade openness, and political stability in the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the data set GrowthData which is included in the package hdm. First, let us load the data set to get familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"RData\")\n",
    "Pkg.add(\"CodecBzip2\")\n",
    "Pkg.add(\"DataStructures\")\n",
    "Pkg.add(\"NamedArrays\")\n",
    "Pkg.add(\"PrettyTables\")\n",
    "Pkg.add(\"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RData, LinearAlgebra, GLM, DataFrames, Statistics, Random, Distributions, DataStructures, NamedArrays, PrettyTables\n",
    "import CodecBzip2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing .Rdata file\n",
    "growth_read = load(\"GitHub/ECO224/data/GrowthData.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since growth_read is a dictionary, we check if there is a key called \"GrowthData\", the one we need for our analyze\n",
    "haskey(growth_read, \"GrowthData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we save that dataframe with a new name\n",
    "growth = growth_read[\"GrowthData\"]\n",
    "names(growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the type and the dimension of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(growth), size(growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample contains $90$ countries and $63$ controls. Thus $p \\approx 60$, $n=90$ and $p/n$ is not small. We expect the least squares method to provide a poor estimate of $\\beta_1$. We expect the method based on partialling-out with Lasso to provide a high quality estimate of $\\beta_1$.\n",
    "\n",
    "To check this hypothesis, we analyze the relation between the output variable $Y$ and the other country's characteristics by running a linear regression in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = growth[!, \"Outcome\"]\n",
    "y = DataFrame([y], [:y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = select(growth, Not([\"Outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [y X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the convergence hypothesis with OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression\n",
    "reg_ols  = lm(term(:y) ~ sum(term.(names(data[!, Not([\"y\", \"intercept\"])]))), data, dropcollinear=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: estimated regression coefficient corresponding to the target regressor\n",
    "est_ols = coef(reg_ols)[2]\n",
    "\n",
    "# output: std. error\n",
    "std_ols = stderror(reg_ols)[2]\n",
    "\n",
    "# output: 95% confidence interval\n",
    "lower_ci = coeftable(reg_ols).cols[5][2]\n",
    "upper_ci = coeftable(reg_ols).cols[6][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the convergence hypothesis with Double LASSO using cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lasso, GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"GLMNet\")\n",
    "using GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = glmnetcv(convert(Matrix,data[!, Not([\"y\", \"intercept\"])]),data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best $\\lambda = 0.004$ for cross validation. Hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = fit(LassoModel, term(:y) ~  sum(term.(names(data[!, Not([\"y\", \"intercept\",\"gdpsh465\"])]))), data;α = 0.004)\n",
    "r_Y = residuals(lasso_model)\n",
    "r_Y = DataFrame([r_Y], [:r_Y])\n",
    "\n",
    "# Part. out d\n",
    "\n",
    "lasso_model = fit(LassoModel, term(:gdpsh465) ~  sum(term.(names(data[!, Not([\"y\", \"intercept\",\"gdpsh465\"])]))), data;  α = 0.004)\n",
    "r_D = residuals(lasso_model)\n",
    "r_D = DataFrame([r_D], [:r_D])\n",
    "\n",
    "# ols \n",
    "data_aux = [r_Y r_D]\n",
    "fm_1 = @formula(r_Y ~ r_D)\n",
    "partial_lasso_fit = lm(fm_1, data_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Lasso using theoretical Lambda (hdmjl.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_reg_0 = rlasso_arg( data[!,4:end], data[!,3:3], nothing, true, true, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "D_resid = rlasso(D_reg_0)[\"residuals\"]\n",
    "\n",
    "Y_reg_0  = rlasso_arg( data[!,4:end], data[!,1:1], nothing, true, true, true, false, false, \n",
    "                    nothing, 1.1, nothing, 5000, 15, 10^(-5), -Inf, true, Inf, true )\n",
    "Y_resid = rlasso(Y_reg_0)[\"residuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_resid = reshape(D_resid, length(D_resid), 1)\n",
    "Lasso_ira = lm(D_resid, Y_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Neyman Orthogonality Proof</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have the following model:\n",
    "\n",
    "$$ Y = \\alpha D + \\beta^{'} W + \\epsilon$$\n",
    "\n",
    "And we make a partialling out procedure:\n",
    "\n",
    "$$\\tilde{Y} = Y - \\gamma_{YW} W $$\n",
    "\n",
    "$$\\tilde{D} = D - \\gamma_{DW} W$$\n",
    "\n",
    "$$\\tilde{Y} = \\alpha \\tilde{D} + \\epsilon$$\n",
    "\n",
    "Note that as $\\alpha$ is a function of $\\tilde{D} , \\tilde{Y}$ it will also be a function of $\\gamma_{YW} , \\gamma_{DW}$. In other words:\n",
    "\n",
    "$$\\eta^0 = (\\gamma_{YW} , \\gamma_{DW})$$\n",
    "\n",
    "$$\\alpha = \\alpha (\\eta^0)$$\n",
    "\n",
    "However, we may only be able to estimate these parameters to a certain degree of precision. \n",
    "\n",
    "$$\\eta = (\\eta_1,\\eta_2) = (\\widehat{\\gamma_{YW}} , \\widehat{\\gamma_{DW}})$$\n",
    "\n",
    "$$\\alpha = \\alpha (\\eta)$$\n",
    "\n",
    "In this regard, the main idea of double Lasso is that $\\alpha$ is locally insensitive (i.e. first-order insensitive) to perturbations on the nuisance parameters ($\\eta$) around their true values. That is:\n",
    "\n",
    "$$\\frac{\\partial \\alpha(\\eta^0)}{\\partial \\eta} = 0$$\n",
    "\n",
    "To prove this, consider the following identity, which is true under the assumptions from the Classical Linear Regression Model:\n",
    "\n",
    "$$ M (a,\\eta) = E \\left[\\left(\\tilde{Y}(\\eta_1)-a\\tilde{D}(\\eta_2)\\right)\\tilde{D}(\\eta_2)\\right] = 0$$\n",
    "\n",
    "**By the implicit function theorem** this last expression turns to\n",
    "\n",
    "$$ \\frac{\\partial M(\\alpha, \\eta^0)}{\\partial a} da + \\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} d\\eta= 0$$\n",
    "\n",
    "$$\\frac{da}{d\\eta} = - \\frac{\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta}}{\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial a}}$$\n",
    "\n",
    "If we examine the numerator, it is possible to make explicit the partial derivative\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = \\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta_1} + \\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta_2} $$\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = E\\left[-W \\tilde{D}(\\eta_2)\\right] + E\\left[-W \\tilde{Y}(\\eta_1) + 2a\\left(W \\tilde{D}(\\eta_2)\\right)\\right] $$\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = -E\\left[W (D - \\gamma_{DW} W)\\right] -E\\left[W(Y - \\gamma_{YW}W)\\right] + 2\\alpha E\\left[W(D-\\gamma_{DW}W)\\right]$$\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = -E\\left[WD - W\\gamma_{DW} W)\\right] -E\\left[WY - W\\gamma_{YW}W)\\right] + 2\\alpha E\\left[WD-W\\gamma_{DW}W)\\right]$$\n",
    "\n",
    "Now recall that:\n",
    "\n",
    "$$\\gamma_{DW} = (W'W)^{-1}W'D$$\n",
    "\n",
    "$$\\gamma_{YW} = (W'W)^{-1}W'Y$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = -E\\left[WD - W \\left[(W'W)^{-1}W'D\\right] W)\\right] -E\\left[WY - W\\left[(W'W)^{-1}W'Y\\right]W)\\right] + 2\\alpha E\\left[WD-W\\left[(W'W)^{-1}W'D\\right]W)\\right]$$\n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = -E\\left[WD - WD\\right] -E\\left[WY - WY\\right] + 2\\alpha E\\left[WD-WD\\right] $$ \n",
    "\n",
    "$$\\frac{\\partial M(\\alpha, \\eta^0)}{\\partial \\eta} = 0 $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "76ae560104ee406d834ff156d8512f0e",
   "lastKernelId": "4174c721-888d-4130-8fce-39b2da4844d6"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
