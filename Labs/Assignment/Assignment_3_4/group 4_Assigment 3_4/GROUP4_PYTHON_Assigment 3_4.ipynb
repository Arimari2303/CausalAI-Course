{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc237bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION NUMBER 1\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81779d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wage',\n",
       " 'lwage',\n",
       " 'sex',\n",
       " 'shs',\n",
       " 'hsg',\n",
       " 'scl',\n",
       " 'clg',\n",
       " 'ad',\n",
       " 'mw',\n",
       " 'so',\n",
       " 'we',\n",
       " 'ne',\n",
       " 'exp1',\n",
       " 'exp2',\n",
       " 'exp3',\n",
       " 'exp4',\n",
       " 'occ',\n",
       " 'occ2',\n",
       " 'ind',\n",
       " 'ind2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Maricielo\\Downloads\\wage2015_subsample_inference.csv')\n",
    "data = data.drop('rownames',axis=1)\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f398e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   const       wage     lwage  sex  shs  hsg  scl  clg   ad   mw  ...   we  \\\n",
      "0    1.0   9.615385  2.263364    0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
      "1    1.0  48.076923  3.872802    0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
      "2    1.0  11.057692  2.403126    0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
      "3    1.0  13.942308  2.634928    0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0   \n",
      "4    1.0  28.846154  3.361977    0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
      "\n",
      "    ne  exp1  exp2    exp3     exp4     occ  occ2     ind  ind2  \n",
      "0  1.0   7.0  0.49   0.343   0.2401  3600.0    11  8370.0    18  \n",
      "1  1.0  31.0  9.61  29.791  92.3521  3050.0    10  5070.0     9  \n",
      "2  1.0  18.0  3.24   5.832  10.4976  6260.0    19   770.0     4  \n",
      "3  1.0  25.0  6.25  15.625  39.0625   420.0     1  6990.0    12  \n",
      "4  1.0  22.0  4.84  10.648  23.4256  2015.0     6  9470.0    22  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from statsmodels.api import add_constant\n",
    "\n",
    "# Transform categorical variables into dummies (assuming 'sex' and 'location' are categorical)\n",
    "# Converting 'sex' into a binary column (0 for 'female', 1 for 'male')\n",
    "data['sex'] = data['sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "# If there are other categorical variables, they can be transformed using OneHotEncoder or pandas.get_dummies\n",
    "# For example, transforming a 'location' column with multiple categories:\n",
    "# data = pd.get_dummies(data, columns=['location'], drop_first=True)\n",
    "\n",
    "# Generate binary interactions\n",
    "# If you need to calculate specific interactions between variables, you can do so manually or programmatically.\n",
    "# Here is an example to create an interaction column between 'treat' and 'sex' (if 'treat' exists):\n",
    "if 'treat' in data.columns:\n",
    "    data['treat_sex_interaction'] = data['treat'] * data['sex']\n",
    "\n",
    "# If you need a dataframe with all the original variables and the interactions:\n",
    "# You can add more interactions similarly.\n",
    "\n",
    "# Optional: Add a constant (intercept) if needed\n",
    "data_with_const = add_constant(data)\n",
    "\n",
    "print(data_with_const.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identified categorical variables \n",
    "categorical_vars = ['sex', 'mw', 'so', 'we', 'ne']  # Gender and locations\n",
    "\n",
    "# Convert categorical variables into dummies\n",
    "data = pd.get_dummies(data, columns=categorical_vars, drop_first=True)\n",
    "\n",
    "# Generate all pairwise interaction terms\n",
    "interaction_terms = []\n",
    "for col1 in data.columns:\n",
    "    for col2 in data.columns:\n",
    "        # Ensure no duplicate interaction terms are created\n",
    "        if col1 != col2 and f\"{col2}*{col1}\" not in interaction_terms:\n",
    "            data[f\"{col1}*{col2}\"] = data[col1] * data[col2]\n",
    "            interaction_terms.append(f\"{col1}*{col2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6746be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target variable and predictors\n",
    "y = data['wage']  # Salary as the dependent variable\n",
    "X = data.drop(columns=['wage'])  # Remaining variables as predictors\n",
    "\n",
    "# Scale the predictor variables for Lasso\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68429187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Fit Lasso model with optimal lambda selection\n",
    "lasso = LassoCV(cv=cv, random_state=42)\n",
    "lasso.fit(X_scaled, y)\n",
    "\n",
    "# Extract coefficients\n",
    "lasso_coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
    "\n",
    "# Display selected coefficients\n",
    "print(\"Selected coefficients by Lasso:\")\n",
    "print(lasso_coefficients[lasso_coefficients != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a845e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model with selected variables\n",
    "selected_features = lasso_coefficients[lasso_coefficients != 0].index\n",
    "X_selected = add_constant(X[selected_features])  # Add constant for regression\n",
    "\n",
    "ols_model = OLS(y, X_selected).fit()\n",
    "\n",
    "# Model summary\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Interpretation: Analyze coefficients\n",
    "impact_clg = lasso_coefficients.filter(like='CLG')  # Filter related to CLG\n",
    "print(\"\\nImpact of being a college graduate in different groups:\")\n",
    "print(impact_clg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73679788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_dag(edges, title):\n",
    "    \"\"\"\n",
    "    Draws a Directed Acyclic Graph (DAG) based on the provided edges.\n",
    "    \n",
    "    Parameters:\n",
    "    - edges: List of tuples representing directed edges (source, target)\n",
    "    - title: Title of the graph\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    pos = nx.spring_layout(G, seed=42)  # Layout for consistent placement\n",
    "    nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"lightblue\", font_size=10, font_weight=\"bold\", arrowsize=15)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# DAG for the first scenario: Tabaquismo y función pulmonar\n",
    "edges_tabaquismo = [\n",
    "    (\"Conducta individual de tabaquismo\", \"Volumen respiratorio forzado\"),\n",
    "    (\"Edad\", \"Conducta individual de tabaquismo\"),\n",
    "    (\"Edad\", \"Volumen respiratorio forzado\"),\n",
    "    (\"Altura\", \"Volumen respiratorio forzado\"),\n",
    "    (\"Sexo\", \"Conducta individual de tabaquismo\"),\n",
    "    (\"Sexo\", \"Volumen respiratorio forzado\")\n",
    "]\n",
    "draw_dag(edges_tabaquismo, \"Efecto del Tabaquismo sobre la Función Pulmonar\")\n",
    "\n",
    "# DAG for the second scenario: Lactancia materna e infecciones\n",
    "edges_lactancia = [\n",
    "    (\"Lactancia materna\", \"Número de infecciones del bebé\"),\n",
    "    (\"Ingresos familiares\", \"Lactancia materna\"),\n",
    "    (\"Ingresos familiares\", \"Número de infecciones del bebé\"),\n",
    "    (\"Educación\", \"Lactancia materna\"),\n",
    "    (\"Educación\", \"Número de infecciones del bebé\"),\n",
    "    (\"Número de niños en el hogar\", \"Lactancia materna\"),\n",
    "    (\"Número de niños en el hogar\", \"Número de infecciones del bebé\"),\n",
    "    (\"Cuidado de niños fuera del hogar\", \"Número de infecciones del bebé\"),\n",
    "    (\"Cuidado de niños fuera del hogar\", \"Lactancia materna\"),\n",
    "    (\"Estado civil\", \"Lactancia materna\"),\n",
    "    (\"Estado civil\", \"Número de infecciones del bebé\")\n",
    "]\n",
    "draw_dag(edges_lactancia, \"Efecto de la Lactancia Materna sobre las Infecciones\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd318a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the Hitters dataset from the ISLR package online\n",
    "url = \"https://raw.githubusercontent.com/sahirbhatnagar/ISLR/master/data/Hitters.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Check the first few rows of the original dataset\n",
    "print(\"First few rows of the original dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Drop missing observations (rows with NaN values)\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Transform categorical variables into dummy variables (one-hot encoding)\n",
    "data_transformed = pd.get_dummies(data_cleaned, drop_first=True)\n",
    "\n",
    "# Show a summary of the transformed dataset\n",
    "print(\"\\nTransformed data:\")\n",
    "print(data_transformed.head())\n",
    "\n",
    "# General information about the transformed dataset\n",
    "print(\"\\nInformation about the transformed data:\")\n",
    "print(data_transformed.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8216289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and clean the Hitters dataset\n",
    "url = \"https://raw.githubusercontent.com/sahirbhatnagar/ISLR/master/data/Hitters.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Drop missing observations\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Transform categorical variables into dummy variables (one-hot encoding)\n",
    "data_transformed = pd.get_dummies(data_cleaned, drop_first=True)\n",
    "\n",
    "# Split the data into training set (90%) and test set (10%)\n",
    "train_data, test_data = train_test_split(data_transformed, test_size=0.1, random_state=42)\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "print(f\"Size of the training set: {len(train_data)}\")\n",
    "print(f\"Size of the test set: {len(test_data)}\")\n",
    "\n",
    "# Optional: Preview the first few rows of each dataset\n",
    "print(\"\\nFirst few rows of the training set:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nFirst few rows of the test set:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import scoreatpercentile\n",
    "\n",
    "# Load and prepare the data\n",
    "url = \"https://raw.githubusercontent.com/sahirbhatnagar/ISLR/master/data/Hitters.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data_cleaned = data.dropna()  # Remove rows with missing values\n",
    "data_transformed = pd.get_dummies(data_cleaned, drop_first=True)  # Transform categorical variables\n",
    "\n",
    "# Split into training (90%) and test (10%) sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data_transformed, test_size=0.1, random_state=42)\n",
    "\n",
    "# Split into X (features) and y (target)\n",
    "X_train = train_data.drop(columns=[\"Salary\"])\n",
    "y_train = train_data[\"Salary\"]\n",
    "X_test = test_data.drop(columns=[\"Salary\"])\n",
    "y_test = test_data[\"Salary\"]\n",
    "\n",
    "# Fit the linear regression model on the training set\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "beta_hat = model.coef_\n",
    "\n",
    "# Prediction and calculation of out-of-sample MSE\n",
    "y_pred = model.predict(X_test)\n",
    "mse_out_sample = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Out-of-sample MSE: {mse_out_sample:.2f}\")\n",
    "\n",
    "# Bootstrap to estimate distributions of coefficients\n",
    "n_iterations = 10000\n",
    "n_samples = X_train.shape[0]\n",
    "bootstrap_betas = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, n_samples=n_samples, random_state=None)\n",
    "    model_bootstrap = LinearRegression()\n",
    "    model_bootstrap.fit(X_resampled, y_resampled)\n",
    "    bootstrap_betas.append(model_bootstrap.coef_)\n",
    "\n",
    "# Convert to matrix for analysis\n",
    "bootstrap_betas = np.array(bootstrap_betas)\n",
    "\n",
    "# Calculate empirical confidence intervals\n",
    "percentiles = [2.5, 97.5]\n",
    "ci_lower = np.percentile(bootstrap_betas, percentiles[0], axis=0)\n",
    "ci_upper = np.percentile(bootstrap_betas, percentiles[1], axis=0)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nEstimated coefficients (OLS) and confidence intervals:\")\n",
    "for idx, col in enumerate(X_train.columns):\n",
    "    print(f\"{col}: β = {beta_hat[idx]:.4f}, 95% CI = [{ci_lower[idx]:.4f}, {ci_upper[idx]:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load and prepare the data\n",
    "url = \"https://raw.githubusercontent.com/sahirbhatnagar/ISLR/master/data/Hitters.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data_cleaned = data.dropna()  # Remove rows with missing values\n",
    "data_transformed = pd.get_dummies(data_cleaned, drop_first=True)  # Convert categorical variables to dummies\n",
    "\n",
    "# Split into training (90%) and test (10%) sets\n",
    "train_data, test_data = train_test_split(data_transformed, test_size=0.1, random_state=42)\n",
    "\n",
    "# Split into X (features) and y (target)\n",
    "X_train = train_data.drop(columns=[\"Salary\"])\n",
    "y_train = train_data[\"Salary\"]\n",
    "X_test = test_data.drop(columns=[\"Salary\"])\n",
    "y_test = test_data[\"Salary\"]\n",
    "\n",
    "# Fit a regression tree with pruning\n",
    "best_alpha = None\n",
    "best_score = float(\"inf\")\n",
    "alphas = np.linspace(0, 0.02, 50)  # Range of alphas for pruning\n",
    "\n",
    "for alpha in alphas:\n",
    "    tree = DecisionTreeRegressor(ccp_alpha=alpha, random_state=42)\n",
    "    scores = -cross_val_score(tree, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    avg_score = scores.mean()  # Average cross-validation score\n",
    "    if avg_score < best_score:\n",
    "        best_score = avg_score\n",
    "        best_alpha = alpha  # Store the best alpha for pruning\n",
    "\n",
    "# Fit the pruned tree with the best alpha\n",
    "tree_pruned = DecisionTreeRegressor(ccp_alpha=best_alpha, random_state=42)\n",
    "tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and MSE calculation for the pruned tree\n",
    "y_pred_tree = tree_pruned.predict(X_test)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"Best ccp_alpha (pruning parameter): {best_alpha}\")\n",
    "print(f\"Out-of-sample MSE of pruned tree: {mse_tree:.2f}\")\n",
    "\n",
    "# Compare with the linear regression model\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "y_pred_linear = model_linear.predict(X_test)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"Out-of-sample MSE of linear regression model: {mse_linear:.2f}\")\n",
    "\n",
    "# Determine which model has the best performance\n",
    "if mse_tree < mse_linear:\n",
    "    print(\"The regression tree has better predictive accuracy.\")\n",
    "else:\n",
    "    print(\"The linear regression model has better predictive accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "###The model with the best performance in terms of predictive accuracy is the one with the lowest Out-of-Sample Mean Squared Error (MSE), as MSE measures how much the model deviates from the actual values, heavily penalizing large errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
