{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(\"../../../../temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\Work\\Documents\\Personal\\Work\\classes\\PUCP 2024-II\\repo\\temp\\temp`\n"
     ]
    }
   ],
   "source": [
    "]activate temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsModels\n",
    "using DataFrames\n",
    "using CSV\n",
    "using GLM\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\n",
    "        download(\"https://raw.githubusercontent.com/d2cml-ai/CausalAI-Course/main/data/wage2015_subsample_inference.csv\"), \n",
    "        DataFrame, \n",
    "        types = Dict(:occ2 => String, :ind2 => String)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:, \"lwage\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now that we have seen the for loops are implemented in Python, they can easily be ported into Julia, so we will not be focusing on that here. However, remember that the formula string methods can cause some issues as they are abstractions of larger procedures \"under the hood,\" meaning that we lose some control over exactly how the generation works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_formula = @formula(lwage ~ 1 + sex + hsg + scl + clg + ad + so + we + ne + exp1 + occ2 + ind2)\n",
    "X_basic = modelmatrix(basic_formula, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexible_formula = @formula(lwage ~ 1 + sex + (exp1 + exp2 + exp3 + exp4) * (hsg + scl + clg + ad + so + we + ne + occ2 + ind2))\n",
    "X_flexible = modelmatrix(flexible_formula, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_flexible_formula = @formula(lwage ~ 1 + sex + (exp1 + exp2 + exp3 + exp4) * (hsg + scl + clg + ad + so + we + ne + occ2 + ind2) + (hsg + scl + clg + ad) * (so + we + ne + occ2 + ind2) + (so + we + ne) * (occ2 + ind2) + occ2 * ind2)\n",
    "X_extra_flexible = modelmatrix(extra_flexible_formula, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0 1.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0], [1.0 1.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 1.0 1.0 … 0.0 0.0; 1.0 1.0 … 0.0 0.0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = rand(Float64, size(data)[1]) .< 0.8\n",
    "test_sample = .!(train_sample)\n",
    "y_train, y_test = y[train_sample], y[test_sample]\n",
    "X_basic_train, X_basic_test = X_basic[train_sample, :], X_basic[test_sample, :]\n",
    "X_flexible_train, X_flexible_test = X_flexible[train_sample, :], X_flexible[test_sample, :]\n",
    "X_extra_flexible_train, X_extra_flexible_test = X_extra_flexible[train_sample, :], X_extra_flexible[test_sample, :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = lm(X_basic_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexible_model = lm(X_flexible_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_flexible_model = lm(X_extra_flexible_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training MSE for the basic model is 0.22355646807078697\n",
      "The training R2 for the basic model is 0.31234132737727915\n",
      "The training Adjusted R2 for the basic model is 0.30363462620951376\n",
      "The testing MSE for the basic model is 0.23099027643329226\n",
      "The testing R2 for the basic model is 0.2924014564471741\n"
     ]
    }
   ],
   "source": [
    "basic_mse_training = mean(residuals(basic_model) .^ 2)\n",
    "basic_r2_training = 1 - basic_mse_training / var(y_train)\n",
    "basic_adjr2_training = 1 - size(y_train)[1] / (size(y_train)[1] - size(X_basic)[2]) * basic_mse_training / var(y_train)\n",
    "basic_mse_testing = mean((predict(basic_model, X_basic_test) - y_test) .^ 2)\n",
    "basic_r2_testing = 1 - basic_mse_testing / var(y_test)\n",
    "\n",
    "println(\"The training MSE for the basic model is $basic_mse_training\")\n",
    "println(\"The training R2 for the basic model is $basic_r2_training\")\n",
    "println(\"The training Adjusted R2 for the basic model is $basic_adjr2_training\")\n",
    "println(\"The testing MSE for the basic model is $basic_mse_testing\")\n",
    "println(\"The testing R2 for the basic model is $basic_r2_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training MSE for the flexible model is 0.2085168129360234\n",
      "The training R2 for the flexible model is 0.35860323773900604\n",
      "The training Adjusted R2 for the flexible model is 0.3174387181678595\n",
      "The testing MSE for the flexible model is 0.23907818049707769\n",
      "The testing R2 for the flexible model is 0.26762556880247357\n"
     ]
    }
   ],
   "source": [
    "flexible_mse_training = mean(residuals(flexible_model) .^ 2)\n",
    "flexible_r2_training = 1 - flexible_mse_training / var(y_train)\n",
    "flexible_adjr2_training = 1 - size(y_train)[1] / (size(y_train)[1] - size(X_flexible)[2]) * flexible_mse_training / var(y_train)\n",
    "flexible_mse_testing = mean((predict(flexible_model, X_flexible_test) - y_test) .^ 2)\n",
    "flexible_r2_testing = 1 - flexible_mse_testing / var(y_test)\n",
    "\n",
    "println(\"The training MSE for the flexible model is $flexible_mse_training\")\n",
    "println(\"The training R2 for the flexible model is $flexible_r2_training\")\n",
    "println(\"The training Adjusted R2 for the flexible model is $flexible_adjr2_training\")\n",
    "println(\"The testing MSE for the flexible model is $flexible_mse_testing\")\n",
    "println(\"The testing R2 for the flexible model is $flexible_r2_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training MSE for the extra_flexible model is 0.17152114446618302\n",
      "The training R2 for the extra_flexible model is 0.47240174463215134\n",
      "The training Adjusted R2 for the extra_flexible model is 0.3089038909295265\n",
      "The testing MSE for the extra_flexible model is 0.28239401244836165\n",
      "The testing R2 for the extra_flexible model is 0.13493505007252615\n"
     ]
    }
   ],
   "source": [
    "extra_flexible_mse_training = mean(residuals(extra_flexible_model) .^ 2)\n",
    "extra_flexible_r2_training = 1 - extra_flexible_mse_training / var(y_train)\n",
    "extra_flexible_adjr2_training = 1 - size(y_train)[1] / (size(y_train)[1] - size(X_extra_flexible)[2]) * extra_flexible_mse_training / var(y_train)\n",
    "extra_flexible_mse_testing = mean((predict(extra_flexible_model, X_extra_flexible_test) - y_test) .^ 2)\n",
    "extra_flexible_r2_testing = 1 - extra_flexible_mse_testing / var(y_test)\n",
    "\n",
    "println(\"The training MSE for the extra_flexible model is $extra_flexible_mse_training\")\n",
    "println(\"The training R2 for the extra_flexible model is $extra_flexible_r2_training\")\n",
    "println(\"The training Adjusted R2 for the extra_flexible model is $extra_flexible_adjr2_training\")\n",
    "println(\"The testing MSE for the extra_flexible model is $extra_flexible_mse_testing\")\n",
    "println(\"The testing R2 for the extra_flexible model is $extra_flexible_r2_testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
