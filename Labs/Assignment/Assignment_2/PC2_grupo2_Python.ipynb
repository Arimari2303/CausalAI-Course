{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC2 - Grupo 2 (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrantes\n",
    "- GARCIA RODRIGUEZ, EMILIO ALONSO\n",
    "- PADILLA AQUISE, ALESSANDRO PIERO\n",
    "- RIEGA NUÑEZ, GABRIEL ANTONIO FERMIN\n",
    "- SALAMANCA FERNANDEZ, LUCAS PABLO\n",
    "- SILVA ANDUJAR, NICOLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading and processing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5150 entries, 0 to 5149\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   rownames  5150 non-null   int64  \n",
      " 1   wage      5150 non-null   float64\n",
      " 2   lwage     5150 non-null   float64\n",
      " 3   sex       5150 non-null   float64\n",
      " 4   shs       5150 non-null   float64\n",
      " 5   hsg       5150 non-null   float64\n",
      " 6   scl       5150 non-null   float64\n",
      " 7   clg       5150 non-null   float64\n",
      " 8   ad        5150 non-null   float64\n",
      " 9   mw        5150 non-null   float64\n",
      " 10  so        5150 non-null   float64\n",
      " 11  we        5150 non-null   float64\n",
      " 12  ne        5150 non-null   float64\n",
      " 13  exp1      5150 non-null   float64\n",
      " 14  exp2      5150 non-null   float64\n",
      " 15  exp3      5150 non-null   float64\n",
      " 16  exp4      5150 non-null   float64\n",
      " 17  occ       5150 non-null   float64\n",
      " 18  occ2      5150 non-null   int64  \n",
      " 19  ind       5150 non-null   float64\n",
      " 20  ind2      5150 non-null   int64  \n",
      "dtypes: float64(18), int64(3)\n",
      "memory usage: 845.1 KB\n"
     ]
    }
   ],
   "source": [
    "data= \"https://raw.githubusercontent.com/d2cml-ai/CausalAI-Course/main/data/wage2015_subsample_inference.csv\"\n",
    "\n",
    "df =pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('rownames')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As in Group Assignment 1 2024 - 2 #1044 , generate the extra-flexible model. This means that it contains all two-way interactions between the experience polynomials and the indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5150, 1378)\n"
     ]
    }
   ],
   "source": [
    "df_with_dummies = pd.get_dummies(df, columns=['occ2', 'ind2'], drop_first=True)\n",
    "extra_flexible_model_vars = ['exp1', 'exp2', 'exp3', 'exp4', 'hsg', 'scl', 'clg', 'ad', \n",
    "                             'so', 'we', 'ne'] + \\\n",
    "                             [col for col in df_with_dummies.columns if col.startswith('occ2_') or col.startswith('ind2_')]\n",
    "\n",
    "two_way_interactions = []\n",
    "for i, var1 in enumerate(extra_flexible_model_vars):\n",
    "    for var2 in extra_flexible_model_vars[i+1:]:\n",
    "        interaction_var = df_with_dummies[var1] * df_with_dummies[var2]\n",
    "        two_way_interactions.append(interaction_var.values.reshape(-1, 1))\n",
    "\n",
    "interactions_array = np.hstack(two_way_interactions)\n",
    "\n",
    "extra_flexible_model_array = np.hstack([df_with_dummies[extra_flexible_model_vars].values, interactions_array])\n",
    "print(extra_flexible_model_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Generate the array for the outcome variable Y and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logwage = df[['lwage']]\n",
    "log_w = np.array(df_logwage['lwage'])\n",
    "log_w = log_w.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr):\n",
    "    min_vals = np.min(arr, axis=0)\n",
    "    max_vals = np.max(arr, axis=0)\n",
    "    # Calcular el rango y evitar la división por cero añadiendo un pequeño valor epsilon\n",
    "    range_vals = max_vals - min_vals\n",
    "    range_vals[range_vals == 0] = 1  # Esto previene la división por cero\n",
    "    norm_arr = (arr - min_vals) / range_vals\n",
    "    return norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22410474]\n",
      " [0.53572233]\n",
      " [0.25116529]\n",
      " ...\n",
      " [0.49251752]\n",
      " [0.46267104]\n",
      " [0.33791134]]\n"
     ]
    }
   ],
   "source": [
    "norm_log_w =normalize_array(log_w)\n",
    "print(norm_log_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14893617021276595 0.022181982797645994 0.0033036995656068506 ... 0.0\n",
      "  0.0 0.0]\n",
      " [0.6595744680851063 0.435038478949751 0.2869402733498358 ... 0.0 0.0 0.0]\n",
      " [0.3829787234042553 0.14667270258035311 0.05617252439247566 ... 0.0 0.0\n",
      "  0.0]\n",
      " ...\n",
      " [0.23404255319148937 0.05477591670439112 0.012819895398900051 ... 0.0\n",
      "  0.0 0.0]\n",
      " [0.2127659574468085 0.04526935264825713 0.009631777159203646 ... 0.0 0.0\n",
      "  0.0]\n",
      " [0.2978723404255319 0.08872793119058398 0.026429596524854805 ... 0.0 0.0\n",
      "  0.0]]\n"
     ]
    }
   ],
   "source": [
    "x_data =normalize_array(extra_flexible_model_array)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split between training and testing samples. The testing sample should be 10% of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ef_model =x_data\n",
    "y=norm_log_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_train,ef_test,y_ef_train,y_ef_test = train_test_split(ef_model,y, train_size= 0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
