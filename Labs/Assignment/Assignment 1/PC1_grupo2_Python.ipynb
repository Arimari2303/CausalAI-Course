{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d2822d-386a-483d-b6dd-11b7df7725c2",
   "metadata": {},
   "source": [
    "# PC1 - Grupo 2 (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dee70b-3d94-4be3-b26f-a6fda49fddfd",
   "metadata": {},
   "source": [
    "#### Integrantes\n",
    "- GARCIA RODRIGUEZ, EMILIO ALONSO\n",
    "- PADILLA AQUISE, ALESSANDRO PIERO\n",
    "- RIEGA NUÃ‘EZ, GABRIEL ANTONIO FERMIN\n",
    "- SALAMANCA FERNANDEZ, LUCAS PABLO\n",
    "- SILVA ANDUJAR, NICOLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb047c1b-d05e-4400-ae75-8358f7f843e5",
   "metadata": {},
   "source": [
    "## 1. Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9280d5bb-68e2-4527-a6d5-e9a6c64b7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e4f2e52-9b6b-4fc7-8cb7-b4a271288d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wage2015_subsample_inference.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e66e5-8849-4d93-8058-45f1f3dd95a7",
   "metadata": {},
   "source": [
    "1.Import the data set. Make sure the column names are imported as intended.d variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cdd3a1c-27d1-49a6-af84-8349bce58af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rownames', 'wage', 'lwage', 'sex', 'shs', 'hsg', 'scl', 'clg', 'ad',\n",
       "       'mw', 'so', 'we', 'ne', 'exp1', 'exp2', 'exp3', 'exp4', 'occ', 'occ2',\n",
       "       'ind', 'ind2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cb34926-6c8c-4976-baca-b67c40440100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('rownames')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5d31b-0f61-4e41-a946-d7f85e808be1",
   "metadata": {},
   "source": [
    "2.Are there missing values? Display the number of missings (if any) of each variable in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "adc773e9-019b-408e-89fc-0b79342e9cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wage     0\n",
      "lwage    0\n",
      "sex      0\n",
      "shs      0\n",
      "hsg      0\n",
      "scl      0\n",
      "clg      0\n",
      "ad       0\n",
      "mw       0\n",
      "so       0\n",
      "we       0\n",
      "ne       0\n",
      "exp1     0\n",
      "exp2     0\n",
      "exp3     0\n",
      "exp4     0\n",
      "occ      0\n",
      "occ2     0\n",
      "ind      0\n",
      "ind2     0\n",
      "dtype: int64\n",
      "There are no missing values\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(missing_values)\n",
    "print(\"There are no missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ad17d-acc9-4f9c-a370-96bdd955755f",
   "metadata": {},
   "source": [
    "3.Report descriptive statistics of the variables (mean, standard deviation, percentiles, etc.). Interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6bd0dee-ca56-43e1-8508-4e537b88e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "      <th>occ</th>\n",
       "      <th>occ2</th>\n",
       "      <th>ind</th>\n",
       "      <th>ind2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.410410</td>\n",
       "      <td>2.970787</td>\n",
       "      <td>0.444466</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.243883</td>\n",
       "      <td>0.278058</td>\n",
       "      <td>0.317670</td>\n",
       "      <td>0.137087</td>\n",
       "      <td>0.259612</td>\n",
       "      <td>0.296505</td>\n",
       "      <td>0.216117</td>\n",
       "      <td>0.227767</td>\n",
       "      <td>13.760583</td>\n",
       "      <td>3.018925</td>\n",
       "      <td>8.235867</td>\n",
       "      <td>25.118038</td>\n",
       "      <td>5310.737476</td>\n",
       "      <td>11.670874</td>\n",
       "      <td>6629.154951</td>\n",
       "      <td>13.316893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.003016</td>\n",
       "      <td>0.570385</td>\n",
       "      <td>0.496955</td>\n",
       "      <td>0.150872</td>\n",
       "      <td>0.429465</td>\n",
       "      <td>0.448086</td>\n",
       "      <td>0.465616</td>\n",
       "      <td>0.343973</td>\n",
       "      <td>0.438464</td>\n",
       "      <td>0.456761</td>\n",
       "      <td>0.411635</td>\n",
       "      <td>0.419432</td>\n",
       "      <td>10.609465</td>\n",
       "      <td>4.000904</td>\n",
       "      <td>14.488962</td>\n",
       "      <td>53.530225</td>\n",
       "      <td>11874.356080</td>\n",
       "      <td>6.966684</td>\n",
       "      <td>5333.443992</td>\n",
       "      <td>5.701019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.021978</td>\n",
       "      <td>1.105912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.461538</td>\n",
       "      <td>2.599837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1740.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4880.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.230769</td>\n",
       "      <td>2.956512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4040.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7370.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.777778</td>\n",
       "      <td>3.324236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>9.261000</td>\n",
       "      <td>19.448100</td>\n",
       "      <td>5610.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8190.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>528.845673</td>\n",
       "      <td>6.270697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>22.090000</td>\n",
       "      <td>103.823000</td>\n",
       "      <td>487.968100</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              wage        lwage          sex          shs          hsg  \\\n",
       "count  5150.000000  5150.000000  5150.000000  5150.000000  5150.000000   \n",
       "mean     23.410410     2.970787     0.444466     0.023301     0.243883   \n",
       "std      21.003016     0.570385     0.496955     0.150872     0.429465   \n",
       "min       3.021978     1.105912     0.000000     0.000000     0.000000   \n",
       "25%      13.461538     2.599837     0.000000     0.000000     0.000000   \n",
       "50%      19.230769     2.956512     0.000000     0.000000     0.000000   \n",
       "75%      27.777778     3.324236     1.000000     0.000000     0.000000   \n",
       "max     528.845673     6.270697     1.000000     1.000000     1.000000   \n",
       "\n",
       "               scl          clg           ad           mw           so  \\\n",
       "count  5150.000000  5150.000000  5150.000000  5150.000000  5150.000000   \n",
       "mean      0.278058     0.317670     0.137087     0.259612     0.296505   \n",
       "std       0.448086     0.465616     0.343973     0.438464     0.456761   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                we           ne         exp1         exp2         exp3  \\\n",
       "count  5150.000000  5150.000000  5150.000000  5150.000000  5150.000000   \n",
       "mean      0.216117     0.227767    13.760583     3.018925     8.235867   \n",
       "std       0.411635     0.419432    10.609465     4.000904    14.488962   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     5.000000     0.250000     0.125000   \n",
       "50%       0.000000     0.000000    10.000000     1.000000     1.000000   \n",
       "75%       0.000000     0.000000    21.000000     4.410000     9.261000   \n",
       "max       1.000000     1.000000    47.000000    22.090000   103.823000   \n",
       "\n",
       "              exp4            occ         occ2            ind         ind2  \n",
       "count  5150.000000    5150.000000  5150.000000    5150.000000  5150.000000  \n",
       "mean     25.118038    5310.737476    11.670874    6629.154951    13.316893  \n",
       "std      53.530225   11874.356080     6.966684    5333.443992     5.701019  \n",
       "min       0.000000      10.000000     1.000000     370.000000     2.000000  \n",
       "25%       0.062500    1740.000000     5.000000    4880.000000     9.000000  \n",
       "50%       1.000000    4040.000000    13.000000    7370.000000    14.000000  \n",
       "75%      19.448100    5610.000000    17.000000    8190.000000    18.000000  \n",
       "max     487.968100  100000.000000    22.000000  100000.000000    22.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1944b2e1-1a3e-44a9-b37b-2277494a56e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wage       19.230769\n",
       "lwage       2.956512\n",
       "sex         0.000000\n",
       "shs         0.000000\n",
       "hsg         0.000000\n",
       "scl         0.000000\n",
       "clg         0.000000\n",
       "ad          0.000000\n",
       "mw          0.000000\n",
       "so          0.000000\n",
       "we          0.000000\n",
       "ne          0.000000\n",
       "exp1       10.000000\n",
       "exp2        1.000000\n",
       "exp3        1.000000\n",
       "exp4        1.000000\n",
       "occ      4040.000000\n",
       "occ2       13.000000\n",
       "ind      7370.000000\n",
       "ind2       14.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fdef86c-8e90-426f-952c-c09944392697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>lwage</th>\n",
       "      <th>sex</th>\n",
       "      <th>shs</th>\n",
       "      <th>hsg</th>\n",
       "      <th>scl</th>\n",
       "      <th>clg</th>\n",
       "      <th>ad</th>\n",
       "      <th>mw</th>\n",
       "      <th>so</th>\n",
       "      <th>we</th>\n",
       "      <th>ne</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>exp4</th>\n",
       "      <th>occ</th>\n",
       "      <th>occ2</th>\n",
       "      <th>ind</th>\n",
       "      <th>ind2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.230769</td>\n",
       "      <td>2.956512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>17</td>\n",
       "      <td>770.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we   ne  \\\n",
       "0  19.230769  2.956512  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   exp1  exp2   exp3    exp4     occ  occ2    ind  ind2  \n",
       "0   5.0  0.25  0.125  0.0625  4700.0    17  770.0    18  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d7209-bf70-4ebc-b1a8-48c51d37d4ef",
   "metadata": {},
   "source": [
    "#### wage:\n",
    "The average wage in the sample is 23.41, with a standard deviation of 21.03, reflecting significant variability in earnings. Wages range from a minimum of 3.02 to a maximum of 528.85, indicating a broad spectrum of income levels. The bottom 25th percentile earn less than 13.46, while the median wage is 19.23, and the top 25% earn more than 27.78. The fact that the median is 19.23 suggests the presence of a number of extremely high wage values, which likely skews the distribution.\n",
    "\n",
    "#### lwage:\n",
    "The logarithm of wage has a mean of 2.97 and a standard deviation of 0.57, suggesting that the distribution of wages in its logarithmic scale is more symmetric than in its original form. The logarithmic wage values range from a minimum of 1.11 to a maximum of 6.27, with the top 25% of the sample having a log wage greater than 3.32. Also, it has a median of 2.96, that suggest a lower presence of extremely high or low wages in the sample. \n",
    "\n",
    "#### sex:\n",
    "Although sex is a dummy variable, we can see that 44% of the sample are females, while the mode is \"male.\" The standard deviation of 0.5 suggests an almost balanced distribution between males and females.\n",
    "\n",
    "#### shs:\n",
    "The \"some high school\" variable shows that only 2.3% of the sample have some incomplete high school education, which represents a small fraction of the total population. \n",
    "\n",
    "#### hsg:\n",
    "About 24% of the sample has graduated from high school, according to the mean of this variable. The standard deviation of 0.43 reflects moderate diversity in the education levels within the sample, with a significant portion not having attained a college degree. \n",
    "\n",
    "#### scl:\n",
    "Approximately 28% of the respondents have attended some college without necessarily graduating, as indicated by the mean. This suggests that a considerable segment of the population has received some tertiary education, although they may not have completed their studies.\n",
    "\n",
    "#### clg:\n",
    "The data shows that 32% of the sample holds a college degree, as reflected in the mean of this variable. This implies that nearly one-third of the sample has completed a college education, which is significant for evaluating human capital.\n",
    "\n",
    "#### ad:\n",
    "About 14% of the individuals in the sample have an advanced degree (master's or doctorate), according to the mean of this variable. This relatively low percentage highlights that advanced education is less common compared to basic college education.\n",
    "\n",
    "#### mw:\n",
    "The Midwest region represents 26% of the sample, as indicated by the mean of this variable. This suggests that this region has significant representation within the dataset.\n",
    "\n",
    "#### so:\n",
    "The South is the most represented region, with 30% of the sample residing in this area, as shown by the mean of this variable. The higher presence of the South may reflect certain geographical trends in the sample.\n",
    "\n",
    "#### we:\n",
    "The West region accounts for 22% of the sample, according to the mean. This proportion suggests a relatively equitable distribution among the country's regions, although with less representation compared to the South.\n",
    "\n",
    "#### ne:\n",
    "The Northeast region represents 23% of the sample, as indicated by the mean of this variable. This proportion, similar to the other regions, shows a relatively balanced geographical distribution in the dataset.\n",
    "\n",
    "#### exp1:\n",
    "The average work experience is 13.76 years, with a standard deviation of 10.61, indicating high variability in the number of years worked among the individuals in the sample. The median is 10 years, meaning that half of the sample has 10 years or less of work experience, while the maximum is 47 years. Also, the mode of work experience is 5.\n",
    "\n",
    "#### exp2:\n",
    "The first polynomial of work experience has a mean of 3.02 years, with a standard deviation of 4.00. This suggests that, for certain specific aspects of work experience, most of the sample has relatively low experience.\n",
    "\n",
    "#### exp3:\n",
    "The second polynomial of work experience, exp3, has a mean of 8.24 years and a standard deviation of 14.49, indicating a wide variability.\n",
    "\n",
    "#### exp4:\n",
    "The third polynomial of work experience, exp4, shows a significantly higher mean of 25.12 years, with a standard deviation of 53.53, again reflecting a high variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490065d-4e9d-4933-8cad-abcf4969b753",
   "metadata": {},
   "source": [
    "4.How many women with a college graduate degree (clg) or above have a wage corresponding to the 25% richest of the sample? Report the dataframe corresponding to this conditions and the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f8af650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we  \\\n",
      "rownames                                                                      \n",
      "19         28.846154  3.361977  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "191        42.307692  3.744969  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "232        41.208791  3.718652  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "319       100.000000  4.605170  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "563        33.653846  3.516127  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
      "...              ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "32251      48.076923  3.872802  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
      "32314      30.145530  3.406037  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
      "32419      29.914530  3.398344  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
      "32567      48.076923  3.872802  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
      "32596      45.546559  3.818735  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
      "\n",
      "           ne  exp1   exp2    exp3      exp4     occ  occ2     ind  ind2  \n",
      "rownames                                                                  \n",
      "19        1.0  22.0   4.84  10.648   23.4256  2015.0     6  9470.0    22  \n",
      "191       1.0   0.0   0.00   0.000    0.0000  4700.0    16  4795.0     9  \n",
      "232       1.0  11.0   1.21   1.331    1.4641  4700.0    16  5790.0     9  \n",
      "319       1.0  27.0   7.29  19.683   53.1441   850.0     2  6970.0    12  \n",
      "563       1.0   4.0   0.16   0.064    0.0256   710.0     2  7390.0    14  \n",
      "...       ...   ...    ...     ...       ...     ...   ...     ...   ...  \n",
      "32251     0.0   0.0   0.00   0.000    0.0000  3050.0    10  8090.0    18  \n",
      "32314     0.0  15.0   2.25   3.375    5.0625   120.0     1  6870.0    12  \n",
      "32419     0.0  39.0  15.21  59.319  231.3441  4700.0    16  5380.0     9  \n",
      "32567     0.0  25.0   6.25  15.625   39.0625  3255.0    10  8170.0    18  \n",
      "32596     0.0   5.0   0.25   0.125    0.0625  3255.0    10  8190.0    18  \n",
      "\n",
      "[419 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "percentile_75_wage = df['wage'].quantile(0.75)\n",
    "rich_ed_women = df[(df['sex'] == 1) & \n",
    "                          ((df['clg'] == 1) | (df['ad'] == 1)) & \n",
    "                          (df['wage'] >= percentile_75_wage)]\n",
    "\n",
    "print(rich_ed_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dce846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of women with a college graduate degree or above in the top 25% richest: 419\n"
     ]
    }
   ],
   "source": [
    "num_rich_ed_women = rich_ed_women.shape[0]\n",
    "print(f\"Number of women with a college graduate degree or above in the top 25% richest: {num_rich_ed_women}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09bc1b-061b-4b61-b740-51ed241385e6",
   "metadata": {},
   "source": [
    "5.How many men with a high school graduate degree (hsg) or below have a wage corresponding to the 25% richest of the sample? Report the dataframe corresponding to this conditions and the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a8a61d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               wage     lwage  sex  shs  hsg  scl  clg   ad   mw   so   we  \\\n",
      "rownames                                                                     \n",
      "113       27.884615  3.328075  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "276       28.846154  3.361977  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "467       28.846154  3.361977  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "858       28.846154  3.361977  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "876       29.714286  3.391628  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...             ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "32191     33.653846  3.516127  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "32254     40.865385  3.710283  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "32281     31.250000  3.442019  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "32321     33.653846  3.516127  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "32631     32.967033  3.495508  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "\n",
      "           ne  exp1   exp2    exp3      exp4     occ  occ2     ind  ind2  \n",
      "rownames                                                                  \n",
      "113       1.0  16.0   2.56   4.096    6.5536  6355.0    19   770.0     4  \n",
      "276       1.0  41.0  16.81  68.921  282.5761  9620.0    22  4970.0     9  \n",
      "467       1.0  33.0  10.89  35.937  118.5921  8220.0    21  3680.0     6  \n",
      "858       1.0  40.0  16.00  64.000  256.0000  4700.0    16  4870.0     9  \n",
      "876       1.0   8.0   0.64   0.512    0.4096  4040.0    13  8680.0    20  \n",
      "...       ...   ...    ...     ...       ...     ...   ...     ...   ...  \n",
      "32191     0.0  30.0   9.00  27.000   81.0000  6320.0    19   770.0     4  \n",
      "32254     0.0  33.0  10.89  35.937  118.5921  7140.0    20  6070.0    10  \n",
      "32281     0.0  34.0  11.56  39.304  133.6336  5400.0    17  9370.0    22  \n",
      "32321     0.0  28.0   7.84  21.952   61.4656  9030.0    22  6070.0    10  \n",
      "32631     0.0  10.0   1.00   1.000    1.0000  2920.0     9  6570.0    11  \n",
      "\n",
      "[118 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "rich_noned_men =df[(df[\"sex\"]== 0) &\n",
    "                   ((df[\"hsg\"]==1) | (df[\"shs\"]==1))&\n",
    "                   (df[\"wage\"]>=percentile_75_wage)]\n",
    "print(rich_noned_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "191469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of men with a high school graduate degree or below in the top 25% richest: 118\n"
     ]
    }
   ],
   "source": [
    "num_rich_noned_men = rich_noned_men.shape[0]\n",
    "print(f\"Number of men with a high school graduate degree or below in the top 25% richest: {num_rich_noned_men}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566b587-9d06-4de1-a0c2-529e436ce9f0",
   "metadata": {},
   "source": [
    "6.Create two dataframes. One containing only the log(wage) and the other containig every variable of the data set but the wage related variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4a5dbc7-c7da-4a80-a29d-1f1f1a690441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe only with lwage\n",
    "df_logwage = df[['lwage']]\n",
    "#Dataframe with rest of the variables but the wage related variable\n",
    "df_nowage =df.drop(columns=['wage', 'lwage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faff603-44c3-4956-9f99-3262e0b3bb0e",
   "metadata": {},
   "source": [
    "## 2. Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e32fd-a8fc-4f91-af3f-91c48e0d2164",
   "metadata": {},
   "source": [
    "7.Make an array for our y \n",
    " variable, which will be the logarithm of wage (lwage column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf08fadc-5529-43fb-a81d-7e6cff2bb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_w = np.array(df_logwage['lwage'])\n",
    "log_w = log_w.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0952f7b-22ca-488b-944f-08a5a4ad0b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26336438]\n",
      " [3.87280229]\n",
      " [2.40312632]\n",
      " ...\n",
      " [3.64965874]\n",
      " [3.49550806]\n",
      " [2.85115104]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5150, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(log_w)\n",
    "log_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe953c4-b604-4ae4-b6cb-409313178e8c",
   "metadata": {},
   "source": [
    "8.Make three new arrays for our predictors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8b88b-5114-4a20-aeb2-72bfbfc9daeb",
   "metadata": {},
   "source": [
    "8.1. The basic model will have the columns sex hsg scl clg ad so we ne exp1 occ2 ind2. Make sure to convert occ2 and ind2 to dummies and to drop the first dummy value to prevent multicolinearity. This means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b839d8ba-6d08-4fce-91f5-6e6e6b393f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wage', 'lwage', 'sex', 'shs', 'hsg', 'scl', 'clg', 'ad', 'mw', 'so',\n",
      "       'we', 'ne', 'exp1', 'exp2', 'exp3', 'exp4', 'occ', 'ind', 'occ2_2',\n",
      "       'occ2_3', 'occ2_4', 'occ2_5', 'occ2_6', 'occ2_7', 'occ2_8', 'occ2_9',\n",
      "       'occ2_10', 'occ2_11', 'occ2_12', 'occ2_13', 'occ2_14', 'occ2_15',\n",
      "       'occ2_16', 'occ2_17', 'occ2_18', 'occ2_19', 'occ2_20', 'occ2_21',\n",
      "       'occ2_22', 'ind2_3', 'ind2_4', 'ind2_5', 'ind2_6', 'ind2_7', 'ind2_8',\n",
      "       'ind2_9', 'ind2_10', 'ind2_11', 'ind2_12', 'ind2_13', 'ind2_14',\n",
      "       'ind2_15', 'ind2_16', 'ind2_17', 'ind2_18', 'ind2_19', 'ind2_20',\n",
      "       'ind2_21', 'ind2_22'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_with_dummies = pd.get_dummies(df, columns=['occ2', 'ind2'], drop_first=True)\n",
    "print(df_with_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10aa0a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5150, 50)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model_vars = ['sex', 'hsg', 'scl', 'clg', 'ad', 'so', 'we', 'ne', 'exp1']\n",
    "basic_model_vars += [col for col in df_with_dummies.columns if col.startswith('occ2_') or col.startswith('ind2_')]\n",
    "#Create the basic model array\n",
    "basic_model_array = df_with_dummies[basic_model_vars].values\n",
    "\n",
    "\n",
    "basic_model_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c88a3",
   "metadata": {},
   "source": [
    "8.2. The flexible model will have the same columns, and will also include polynomials for experience (exp2 exp3 exp4), as well as the interactions between all experience variables and other variables except for sex. This means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "172abd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5150, 245)\n"
     ]
    }
   ],
   "source": [
    "flexible_model_vars = basic_model_vars + ['exp2', 'exp3', 'exp4']\n",
    "\n",
    "interactions = []\n",
    "for exp in ['exp1', 'exp2', 'exp3', 'exp4']:\n",
    "    for var in ['hsg', 'scl', 'clg', 'ad', 'so', 'we', 'ne'] + \\\n",
    "               [col for col in df_with_dummies.columns if col.startswith('occ2_') or col.startswith('ind2_')]:\n",
    "        interaction_var = df_with_dummies[exp] * df_with_dummies[var]\n",
    "        interactions.append(interaction_var.values.reshape(-1, 1))\n",
    "\n",
    "flexible_model_array = np.hstack([df_with_dummies[flexible_model_vars].values] + interactions)\n",
    "\n",
    "print(flexible_model_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74a5e1",
   "metadata": {},
   "source": [
    "8.3. The extra-flexible model will include all two-way interactions between variables, except for sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adec31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5150, 1378)\n"
     ]
    }
   ],
   "source": [
    "extra_flexible_model_vars = ['exp1', 'exp2', 'exp3', 'exp4', 'hsg', 'scl', 'clg', 'ad', \n",
    "                             'so', 'we', 'ne'] + \\\n",
    "                             [col for col in df_with_dummies.columns if col.startswith('occ2_') or col.startswith('ind2_')]\n",
    "\n",
    "two_way_interactions = []\n",
    "for i, var1 in enumerate(extra_flexible_model_vars):\n",
    "    for var2 in extra_flexible_model_vars[i+1:]:\n",
    "        interaction_var = df_with_dummies[var1] * df_with_dummies[var2]\n",
    "        two_way_interactions.append(interaction_var.values.reshape(-1, 1))\n",
    "\n",
    "interactions_array = np.hstack(two_way_interactions)\n",
    "\n",
    "extra_flexible_model_array = np.hstack([df_with_dummies[extra_flexible_model_vars].values, interactions_array])\n",
    "\n",
    "print(extra_flexible_model_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8effc",
   "metadata": {},
   "source": [
    "9.Normalize all the variables, including Y. This means that for each variable V, create V~:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75a4a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays successfully converted to float.\n"
     ]
    }
   ],
   "source": [
    "def normalize_array(arr):\n",
    "    mean = np.mean(arr, axis=0)\n",
    "    std_dev = np.std(arr, axis=0)\n",
    "    \n",
    "    # Prevent SD that are 0\n",
    "    std_dev[std_dev == 0] = 1  \n",
    "    \n",
    "    normalized_array = (arr - mean) / std_dev\n",
    "    return normalized_array\n",
    "\n",
    "\n",
    "try:\n",
    "    basic_model_array = basic_model_array.astype(float)\n",
    "    flexible_model_array = flexible_model_array.astype(float)\n",
    "    extra_flexible_model_array = extra_flexible_model_array.astype(float)\n",
    "    log_w = log_w.astype(float)\n",
    "    print(\"All arrays successfully converted to float.\")\n",
    "except ValueError as e:\n",
    "    print(\"Error converting to float:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33b9512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For our Y (log_w)\n",
    "norm_log_w = normalize_array(log_w)\n",
    "\n",
    "#For basic model\n",
    "normalized_basic_model_array = normalize_array(basic_model_array)\n",
    "\n",
    "# For flexible model\n",
    "normalized_flexible_model_array = normalize_array(flexible_model_array)\n",
    "\n",
    "# For extra flexible model\n",
    "normalized_extra_flexible_model_array = normalize_array(extra_flexible_model_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba4b15",
   "metadata": {},
   "source": [
    "## 3. Linear Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182e0a8",
   "metadata": {},
   "source": [
    "10. Split each of the dataframes created (basic, flexible and extra-flexible models) into a training sample (80% of the data) and a test sample. Use the normalized data for this. Hint: You do not need to normalize the data for dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2213215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of only continuos variables \n",
    "\n",
    "continuous_vars = ['exp1', 'exp2', 'exp3', 'exp4', 'hsg', 'scl', 'clg', 'ad', 'so', 'we', 'ne']\n",
    "\n",
    "normalized_continuous_array = normalize_array(df_with_dummies[continuous_vars].values)\n",
    "\n",
    "dummy_vars = [col for col in df_with_dummies.columns if col.startswith('occ2_') or col.startswith('ind2_')]\n",
    "\n",
    "#Basic Model\n",
    "continuous_vars_basic = ['hsg', 'scl', 'clg', 'ad', 'so', 'we', 'ne', 'exp1']\n",
    "normalized_continuous_basic = normalize_array(df_with_dummies[continuous_vars_basic].values)\n",
    "\n",
    "normalized_basic_model_array = np.hstack([\n",
    "    df_with_dummies[['sex']].values,  \n",
    "    normalized_continuous_basic,       \n",
    "    df_with_dummies[dummy_vars].values \n",
    "])\n",
    "\n",
    "\n",
    "#Flexible Model \n",
    "# Continuous variables for the flexible model\n",
    "continuous_vars_flexible = continuous_vars_basic + ['exp2', 'exp3', 'exp4']\n",
    "normalized_continuous_flexible = normalize_array(df_with_dummies[continuous_vars_flexible].values)\n",
    "\n",
    "interactions = []\n",
    "for exp in ['exp1', 'exp2', 'exp3', 'exp4']:\n",
    "    for var in ['hsg', 'scl', 'clg', 'ad', 'so', 'we', 'ne'] + dummy_vars:\n",
    "        interaction_var = df_with_dummies[exp] * df_with_dummies[var]\n",
    "        interactions.append(interaction_var.values.reshape(-1, 1))\n",
    "\n",
    "normalized_flexible_model_array = np.hstack([normalized_continuous_flexible, df_with_dummies[dummy_vars].values] + interactions)\n",
    "\n",
    "#For the Extra-Flexible Model\n",
    "normalized_continuous_extra_flexible = normalize_array(df_with_dummies[continuous_vars_flexible].values)\n",
    "\n",
    "normalized_extra_flexible_model_array = np.hstack([normalized_continuous_extra_flexible, df_with_dummies[dummy_vars].values, interactions_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c307d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "b_model = normalized_basic_model_array\n",
    "f_model = normalized_flexible_model_array\n",
    "ef_model = normalized_continuous_extra_flexible\n",
    "\n",
    "y = norm_log_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab2d7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train,b_test,y_b_train,y_b_test = train_test_split(b_model,y, train_size= 0.8)\n",
    "f_train,f_test,y_f_train,y_f_test = train_test_split(f_model,y, train_size= 0.8)\n",
    "ef_train,ef_test,y_ef_train,y_ef_test = train_test_split(ef_model,y, train_size= 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6fd47",
   "metadata": {},
   "source": [
    "11. Estimate all three models\n",
    "\n",
    "- basic\n",
    "- flexible\n",
    "- extra-flexible model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb4da7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "\n",
    "# Basic model \n",
    "model_b = LinearRegression()\n",
    "model_b.fit(b_train,y_b_train)\n",
    "\n",
    "#Flexible model\n",
    "model_f = LinearRegression()\n",
    "model_f.fit(f_train,y_f_train)\n",
    "\n",
    "#Extra flexible model\n",
    "model_ef = LinearRegression()\n",
    "model_ef.fit(ef_train,y_ef_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12446fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict_test\n",
    "y_b_hat_test = model_b.predict(b_test)\n",
    "y_f_hat_test = model_f.predict(f_test)\n",
    "y_ef_hat_test = model_ef.predict(ef_test)\n",
    "\n",
    "#Predict_train\n",
    "y_b_hat_train = model_b.predict(b_train)\n",
    "y_f_hat_train = model_f.predict(f_train)\n",
    "y_ef_hat_train = model_ef.predict(ef_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7a06b",
   "metadata": {},
   "source": [
    "12. Report the MSE and the R2 for both samples of each model, and the adjusted R2 for the training sample. Do we see overfitting? Which model has the best out-of-sample performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdd9f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE out of sample of the basic model is 0.6949035167471324\n",
      "MSE out of sample of the flexible model is 0.7845450292138585\n",
      "MSE out of sample of the extra flexible is 0.8185159589226129\n",
      "MSE of sample of the basic model is 0.6902736402438732\n",
      "MSE of sample of the flexible model is 0.6310864035986009\n",
      "MSE of sample of the extra flexible is 0.8192693882469149\n",
      "R-squared out of sample of the basic model is 0.3137175050004656\n",
      "R-squared out of sample of the flexible model is 0.2918296253373194\n",
      "R-squared out of sample of the extra flexible model is 0.18148410256207892\n",
      "R-squared out of sample of the basic model is 0.3074989471507793\n",
      "R-squared out of sample of the flexible model is 0.3513073491458393\n",
      "R-squared out of sample of the extra flexible model is 0.18024843561720316\n",
      "Adjusted R-squared in sample of the basic model is 0.29899156320914266\n",
      "Adjusted R-squared in sample of the flexible model  is 0.3102932331563504\n",
      "Adjusted R-squared in sample of the extra flexible model is -0.23172007485671897\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MSE - Out of sample\n",
    "\n",
    "mse_b_test = np.mean((y_b_test - y_b_hat_test) ** 2)\n",
    "mse_f_test = np.mean((y_f_test - y_f_hat_test) ** 2)\n",
    "mse_ef_test = np.mean((y_ef_test - y_ef_hat_test) ** 2)\n",
    "\n",
    "print(f'MSE out of sample of the basic model is {mse_b_test}')\n",
    "print(f'MSE out of sample of the flexible model is {mse_f_test}')\n",
    "print(f'MSE out of sample of the extra flexible is {mse_ef_test}')\n",
    "\n",
    "# MSE - Sample\n",
    "\n",
    "mse_b_train = np.mean((y_b_train - y_b_hat_train) ** 2)\n",
    "mse_f_train = np.mean((y_f_train - y_f_hat_train) ** 2)\n",
    "mse_ef_train = np.mean((y_ef_train - y_ef_hat_train) ** 2)\n",
    "\n",
    "print(f'MSE of sample of the basic model is {mse_b_train}')\n",
    "print(f'MSE of sample of the flexible model is {mse_f_train}')\n",
    "print(f'MSE of sample of the extra flexible is {mse_ef_train}')\n",
    "\n",
    "# R-squared - Out of sample\n",
    "\n",
    "R_sq_1_test = 1 - mse_b_test / np.mean((y_b_test-np.mean(y_b_test))** 2)\n",
    "R_sq_2_test = 1 - mse_f_test / np.mean((y_f_test-np.mean(y_f_test))** 2)\n",
    "R_sq_3_test = 1 - mse_ef_test / np.mean((y_ef_test-np.mean(y_ef_test))** 2)\n",
    "\n",
    "print(f'R-squared out of sample of the basic model is {R_sq_1_test}')\n",
    "print(f'R-squared out of sample of the flexible model is {R_sq_2_test}')\n",
    "print(f'R-squared out of sample of the extra flexible model is {R_sq_3_test}')\n",
    "\n",
    "# R-squared - Sample\n",
    "R_sq_1_train = 1 - mse_b_train / np.mean((y_b_train-np.mean(y_b_train))** 2)\n",
    "R_sq_2_train = 1 - mse_f_train / np.mean((y_f_train-np.mean(y_f_train))** 2)\n",
    "R_sq_3_train = 1 - mse_ef_train / np.mean((y_ef_train-np.mean(y_ef_train))** 2)\n",
    "\n",
    "print(f'R-squared out of sample of the basic model is {R_sq_1_train}')\n",
    "print(f'R-squared out of sample of the flexible model is {R_sq_2_train}')\n",
    "print(f'R-squared out of sample of the extra flexible model is {R_sq_3_train}')\n",
    "\n",
    "# Adjusted R-squared\n",
    "\n",
    "n = 5150 \n",
    "n_sample = n * 0.8\n",
    "\n",
    "adj_mse_1_train = n_sample / (n_sample-50) * mse_b_train\n",
    "adjR_sq_1_train = 1 - adj_mse_1_train / np.mean((y_b_train-np.mean(y_b_train))** 2)\n",
    "\n",
    "adj_mse_2_train = n_sample / (n_sample-245) * mse_f_train\n",
    "adjR_sq_2_train = 1 - adj_mse_2_train / np.mean((y_f_train-np.mean(y_f_train))** 2)\n",
    "\n",
    "adj_mse_3_train = n_sample/ (n_sample-1378) * mse_ef_train\n",
    "adjR_sq_3_train = 1 - adj_mse_3_train / np.mean((y_ef_train-np.mean(y_ef_train))** 2)\n",
    "\n",
    "print(f'Adjusted R-squared in sample of the basic model is {adjR_sq_1_train}')\n",
    "print(f'Adjusted R-squared in sample of the flexible model  is {adjR_sq_2_train}')\n",
    "print(f'Adjusted R-squared in sample of the extra flexible model is {adjR_sq_3_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b8167",
   "metadata": {},
   "source": [
    "These results show that overfitting is present in the extra flexible model. This is visible when we compare the values between its R-squared and adjusted R-squared, as the value reduces drastically from 0.35 to -0.23, which means that the addition of more regressors does not improve the model's fit (a feature of overfitting). In that sense, the model with the best out of sample performance is the basic model, due to having the smallest out of sample MSE value (0.69) and highest out of sample R-squared value (0.31) compared to the other models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
