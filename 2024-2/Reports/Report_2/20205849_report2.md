## Report 2: Inference for High-Dimensional Sparse Econometric Models (Belloni, Chenozhukov & Hansen, 2011)

### Student: Lucas Salamanca Fernández
### Code: 20205849

The paper provides new estimation methods and techniques for high dimensional sparse (HDS) regression models in econometrics. HDS models allows for a large number of regressors to be used, including the possibility of p (number of regressors) be larger than n (sample size). This can create problems in the estimation, as many of the regressors might not add any explanation value, leading to further issues, such as overfitting. In that sense, the paper presents new techniques that involve the use sparse models, which limit the number of regressors to only those that have a significant effect on the dependent variable. Thus, the goal of the paper is to introduce new $l_1$ penalization methods to effectively select the number of regressors and improve the statistical inference of the models. The paper specifically dives in the use of such $l_1$ penalization methods in instrumental variable models and the partially linear model. Finally, the paper provides two applied examples: Angrist and Krueger Example with 1530 instruments and an Economic Growth Example. Both of which provide effective ways in which the $l_1$ penalization can be implemented to improve statistical inference.

Overall, the paper manages to present the most recent theoretical advancements on causal inference in a way that beginners can understand most of it, starting from the simplest CEF built with approximating polynomial functions to more theoretically complex models such as Post-Iterated Lasso or computationally complex such as CV Post-Lasso. I believe it was successful in explaining basic concepts, such as the penalization parameter, shrinkage bias, the advantages of a method to be pivotal, and the uniformity critique, among others.

Another strength of the paper is the empirical testing that follows the theoretical explanations. I believe that this approach is effective in proving, via Montecarlo simulations, how well designed $l_1$ penalization methods can approximate the data-generating process with a smaller bias and error than more conventional models. It also allows readers to circle back and have a more complete understanding of the models, specifically with the use of the applied examples of (1) Angrist and Krueger and (2) Economic Growth (although real data was used in these examples). 

Nevertheless, some limitations from this paper arise in the computational side, for example when dealing with a CV Post-Lasso model. This can limit certain users from exploring this model and exploit it benefits. Another issue with these type of models can be a lack of economic intuition/theory for choosing the regressors. In the case of Lasso there is no a priori information about which variables are important in a theoretical way. This can lead to a weak theoretical back up in certain models. Even though it was highlighted that in the example of Angrist and Krueger the model rightfully chose the most important dummy (birth in the fourth quarter), it was chosen from a statistical advantage and not from an economic one. Thus, this allows for variables that might not be related in a theoretical sense to play an important role in an empirical approach. One should be careful with this. 

On a different note, the paper goes a step further and highlights some of the limitations that the Lasso method has in suffering from omitted variables bias. Thus, the authors present a new method, named the “double-Post-Lasso”, which allows for a higher chance of successfully recovering terms that approximate the key control term $m(z_i)$, which then leads to improved robustness properties. After the simulations, this method also presents the smallest mean bias and standard deviation, which greatly advances the techniques for HDS models.

A comprehensible next step for this question would be to target the uniformity critique from the “double-Post-Lasso” method, as it does not achieve “full” uniformity. Although it is not a deficiency, it would be relevant to analyse specific dgps sequences for which the method does not achieve validity, understand its properties and propose alternative methods for these. 
