# Bootstrap

```{python}
import pandas as pd
import statsmodels.formula.api as smf
import numpy as np
```


## Read Data

```{python}
pen = "https://raw.githubusercontent.com/alexanderquispe/CausalAI-Course/main/data/penn_jae.csv"
data = pd.read_csv(pen)
data.columns
```

## Filter


```{python}
data = data[data['tg'].isin([0, 4])]
data['T4'] = np.where(data['tg'] == 4, 1, 0)
data['log_inuidur1'] = np.log(data["inuidur1"])
```

## Model 

```{python}
def model_ols(data, formula = 'log_inuidur1 ~ T4 + female + black + othrace + dep + q2 + q3 + q4 + q5 + q6 + agelt35 + agegt54 + durable + lusd + husd'):
    md = smf.ols(formula, data=data).fit()
    return md
md0 = model_ols(data)
md0.summary()
```

## Bootstrap

```{python}
n_bootstrap = 1000
coef_tg = np.zeros(n_bootstrap)
coef_female = np.zeros(n_bootstrap)
coef_black = np.zeros(n_bootstrap)

n = len(data)

for i in range(n_bootstrap):
    sample_data = data.sample(n=n, replace=True)
    model_i = model_ols(sample_data)
    coef_tg[i] = model_i.params['T4']
    coef_female[i] = model_i.params['female']
    coef_black[i] = model_i.params['black']

se_tg = np.std(coef_tg)
se_female = np.std(coef_female)
se_black = np.std(coef_black)
mean_tg = np.mean(coef_tg)
mean_female = np.mean(coef_female)
mean_black = np.mean(coef_black)
```


```{python}
import matplotlib.pyplot as plt

plt.hist(coef_tg, label = "tg");
plt.hist(coef_female, label = 'female');
plt.hist(coef_black, label = 'black');
plt.legend();
```


## Results

```{python}
results = pd.DataFrame({
    'Variable': ['T4 (TG)', 'female', 'black'],
    "Mean Coef": [mean_tg, mean_female, mean_black],
    'Bootstrap SE': [se_tg, se_female, se_black]
})
results
```


# Causal Trees


```{python}
# Causal forest libraries
import statsmodels.api as sm
from econml.grf import RegressionForest
from econml.dml import CausalForestDML
from econml.cate_interpreter import SingleTreeCateInterpreter
```

## Data

```{python}
s_data = pd.read_csv(
    "https://raw.githubusercontent.com/alexanderquispe/CausalAI-Course/main/data/synthetic_data.csv"
)


Y = s_data["Y"]
T = s_data["Z"]
X = s_data.drop(columns=["schoolid", "Z", "Y", "C1", "XC"])
W = None
```

## GLM

```{python}
formula = 'Z ~ ' + ' + '.join(s_data.columns.drop(['Z', 'Y']))
w_lm = smf.glm(formula=formula, data=s_data, family=sm.families.Binomial()).fit()
```

## Causal Forest

```{python}
np.random.seed(123)

cmf_model = CausalForestDML(
    model_t=RegressionForest(),
    model_y=RegressionForest(),
    n_estimators=200,
    min_samples_leaf=4,
    max_depth=50,
    verbose=0,
    random_state=123,
)

model = cmf_model.fit(Y, T, X=X, W=W)

intrp = SingleTreeCateInterpreter(max_depth=2).interpret(cmf_model, X)
intrp.plot(feature_names=X.columns, fontsize=7)
```


```{python}
tau_hat = cmf_model.effect(X=X)  # tau(X) estimates
tau_mean = np.mean(tau_hat)
plt.hist(tau_hat)
plt.axvline(tau_mean)

```


## Linear Predictor

```{python}
effect = tau_hat > tau_mean

ate_high = tree_model.ate_inference(X=X[effect])
ate_low = tree_model.ate_inference(X=X[~effect])
```